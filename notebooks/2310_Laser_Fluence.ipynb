{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "\n",
    "Import python libraries as well as the self written FERMI library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from os.path import join, split\n",
    "from getpass import getuser\n",
    "from glob import glob\n",
    "from time import strftime\n",
    "from importlib import reload\n",
    "from copy import deepcopy\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# data\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import h5py\n",
    "\n",
    "# Images\n",
    "import imageio\n",
    "from imageio import imread\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import NonUniformImage\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.path import Path\n",
    "\n",
    "#pyFAI\n",
    "import pyFAI\n",
    "pyFAI.disable_opencl=True # get rid of annoying warning ;)\n",
    "from pyFAI.azimuthalIntegrator import AzimuthalIntegrator\n",
    "from pyFAI.detectors import Detector\n",
    "\n",
    "# Scipy\n",
    "from scipy.ndimage.filters import median_filter \n",
    "\n",
    "# Self-written libraries\n",
    "import process_FERMI as pf\n",
    "from process_FERMI import interactive\n",
    "from proces_FERMI.interactive import cimshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# interactive plotting\n",
    "import ipywidgets\n",
    "%matplotlib widget\n",
    "plt.rcParams[\"figure.constrained_layout.use\"] = True\n",
    "\n",
    "# Auto formatting of cells\n",
    "%load_ext jupyter_black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folder(folder):\n",
    "    \"\"\"\n",
    "    Creates input folder if it does not exist yet\n",
    "    \"\"\"\n",
    "\n",
    "    if not (os.path.exists(folder)):\n",
    "        print(\"Creating folder \" + folder)\n",
    "        os.makedirs(folder)\n",
    "    return folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_exp_OF(datafolder, keys=None, sort=False):\n",
    "    # Loading experiment data\n",
    "    extension = \"_OF\"\n",
    "    exp = pf.get_exp_dataframe(datafolder + extension, keys=keys)\n",
    "    for k in [\"xgm_UH\", \"xgm_SH\", \"diode_sum\"]:\n",
    "        exp[k + \"_sum\"] = exp[k].apply(np.sum)\n",
    "\n",
    "    exp[\"diode_sum_mean\"] = exp.diode_sum.apply(np.mean)\n",
    "    exp[\"diode_sum_std\"] = exp.diode_sum.apply(np.std)\n",
    "    exp[\"IR_mean\"] = exp.IR.apply(np.mean)\n",
    "    exp[\"IR_std\"] = exp.IR.apply(np.std)\n",
    "    exp[\"magnet_mean\"] = exp.magnet.apply(np.mean)\n",
    "    exp[\"magnet_mean\"] = exp.magnet_mean.apply(np.round, args=(3,))\n",
    "    exp[\"bunchid\"] = exp.bunches.apply(lambda l: l[-1])\n",
    "\n",
    "    if sort is True:\n",
    "        exp = exp.sort_values(scan_axis)\n",
    "\n",
    "    # Loading image data\n",
    "    exp[\"images\"] = [\n",
    "        pf.loadh5(fname, extra_keys=[\"alignz\", \"PAM/FQPDSum\"])[0]\n",
    "        for fname in exp[\"filename\"]\n",
    "    ]\n",
    "\n",
    "    return exp\n",
    "\n",
    "\n",
    "def preprocess_exp_BG(datafolder, keys=None):\n",
    "    # Loading background exp dataframe\n",
    "    extension = \"_BG\"\n",
    "    exp_bg = pf.get_exp_dataframe(datafolder + extension, keys=keys)\n",
    "    exp_bg[\"bunchid\"] = exp.bunches.apply(lambda l: l[-1])\n",
    "    exp_bg = exp_bg.sort_values(\"time\")\n",
    "\n",
    "    # Loading background data\n",
    "    exp_bg[\"images\"] = [\n",
    "        pf.loadh5(fname, extra_keys=[\"alignz\", \"PAM/FQPDSum\"])[0]\n",
    "        for fname in exp_bg[\"filename\"]\n",
    "    ]\n",
    "\n",
    "    return exp_bg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw circle mask\n",
    "def circle_mask(shape, center, radius, sigma=\"none\"):\n",
    "    \"\"\"\n",
    "    Draws circle mask with option to apply gaussian filter for smoothing\n",
    "\n",
    "    Parameter\n",
    "    =========\n",
    "    shape : int tuple\n",
    "        shape/dimension of output array\n",
    "    center : int tuple\n",
    "        center coordinates (ycenter,xcenter)\n",
    "    radius : scalar\n",
    "        radius of mask in px. Care: diameter is always (2*radius+1) px\n",
    "    sigma : scalar\n",
    "        std of gaussian filter\n",
    "\n",
    "    Output\n",
    "    ======\n",
    "    mask: array\n",
    "        binary mask, or smoothed binary mask\n",
    "    ======\n",
    "    author: ck 2022\n",
    "    \"\"\"\n",
    "\n",
    "    # setup array\n",
    "    x = np.linspace(0, shape[1] - 1, shape[1])\n",
    "    y = np.linspace(0, shape[0] - 1, shape[0])\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "\n",
    "    # define circle\n",
    "    mask = np.sqrt(((X - center[1]) ** 2 + (Y - center[0]) ** 2)) <= (radius)\n",
    "    mask = mask.astype(float)\n",
    "\n",
    "    # smooth aperture\n",
    "    if sigma != \"none\":\n",
    "        mask = scipy.ndimage.filters.gaussian_filter(mask, sigma)\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def create_single_polygon_mask(shape, coordinates):\n",
    "    \"\"\"\n",
    "    Creates a polygon mask from coordinates of corner points\n",
    "\n",
    "    Parameter\n",
    "    =========\n",
    "    shape : int tuple\n",
    "        shape/dimension of output array\n",
    "    coordinates: nested list\n",
    "        coordinates of polygon corner points [[yc_1,xc_1],[yc_2,xc_2],...]\n",
    "\n",
    "\n",
    "    Output\n",
    "    ======\n",
    "    mask: array\n",
    "        binary mask where filled polygon is \"1\"\n",
    "    ======\n",
    "    author: ck 2023\n",
    "    \"\"\"\n",
    "\n",
    "    x, y = np.meshgrid(np.arange(shape[0]), np.arange(shape[1]))\n",
    "    x, y = x.flatten(), y.flatten()\n",
    "\n",
    "    points = np.vstack((x, y)).T\n",
    "\n",
    "    path = Path(coordinates)\n",
    "    mask = path.contains_points(points)\n",
    "    mask = mask.reshape(shape)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def create_polygon_mask(shape, coordinates):\n",
    "    \"\"\"\n",
    "    Creates multiple polygon masks from set of coordinates of corner points\n",
    "\n",
    "    Parameter\n",
    "    =========\n",
    "    shape : int tuple\n",
    "        shape/dimension of output array\n",
    "    coordinates: nested list\n",
    "        coordinates of polygon corner points for multiple polygons\n",
    "        [[[yc_1,xc_1],[yc_2,xc_2],...],[[yc_1,xc_1],[yc_2,xc_2],...]]\n",
    "\n",
    "    Output\n",
    "    ======\n",
    "    mask: array\n",
    "        binary mask where filled polygons are \"1\"\n",
    "    ======\n",
    "    author: ck 2023\n",
    "    \"\"\"\n",
    "\n",
    "    if len(coordinates) == 1:\n",
    "        mask = create_single_polygon_mask(shape, coordinates[0])\n",
    "    elif len(coordinates) > 1:\n",
    "        mask = np.zeros(shape)\n",
    "        for coord in coordinates:\n",
    "            mask = mask + create_single_polygon_mask(shape, coord)\n",
    "            mask[mask > 1] = 1\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def load_poly_masks(polygon_name_list, shape):\n",
    "    \"\"\"\n",
    "    Loads set of polygon masks based on stored coordinates\n",
    "\n",
    "    Parameter\n",
    "    =========\n",
    "    polygon_name_list : list\n",
    "        shape/dimension of output array\n",
    "\n",
    "\n",
    "    Output\n",
    "    ======\n",
    "    mask: array\n",
    "        binary mask where filled polygons are \"1\"\n",
    "    ======\n",
    "    author: ck 2023\n",
    "    \"\"\"\n",
    "\n",
    "    mask = []\n",
    "    for polygon_name in polygon_name_list:\n",
    "        coord = load_poly_coordinates(polygon_name)\n",
    "        mask.append(create_polygon_mask(shape, [coord]).astype(float))\n",
    "\n",
    "    mask = np.array(mask)\n",
    "    mask = np.sum(mask, axis=0)\n",
    "    mask[mask > 1] = 1\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define basic folders\n",
    "BASEFOLDER = r\"/net/online4diproi/store/\"\n",
    "PROPOSAL = \"20224053\"\n",
    "basefolder = join(BASEFOLDER, PROPOSAL)\n",
    "USER = getuser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict with most basic experimental parameter\n",
    "experimental_setup = {\n",
    "    \"ccd_dist\": 0.103,  # ccd to sample distance\n",
    "    \"px_size\": 11e-6,  # pixel_size of camera\n",
    "    \"binning\": 1,  # Camera binning\n",
    "}\n",
    "\n",
    "# Setup for azimuthal integrator\n",
    "detector = Detector(\n",
    "    experimental_setup[\"binning\"] * experimental_setup[\"px_size\"],\n",
    "    experimental_setup[\"binning\"] * experimental_setup[\"px_size\"],\n",
    ")\n",
    "\n",
    "# General saving folder\n",
    "folder_general = create_folder(join(basefolder, \"results\", \"processed\", USER))\n",
    "print(\"Output Folder: %s\" % folder_general)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Scan ids for loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define scans for loading\n",
    "sample = \"S2205ref\"\n",
    "membrane = \"H2\"\n",
    "scan_id = np.arange(33, 40)\n",
    "\n",
    "scans = [f\"%s_HystScan_Inverted_%03d\" % (membrane, idx) for idx in scan_id]\n",
    "scans.pop(2)\n",
    "print(\"Loading folders:%s\" % scans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Xarray keys\n",
    "xr_keys = [\"diode_sum_mean\", \"diode_sum_std\", \"IR_mean\", \"IR_std\", \"magnet_mean\"]\n",
    "\n",
    "# Extra keys for loading\n",
    "extra_keys = {\n",
    "    \"diode_sum\": \"PAM/FQPDSum\",\n",
    "    \"IR\": \"Laser/Energy1\",\n",
    "    \"magnet\": \"DPI/CoilCurrent\",\n",
    "    \"bunches\": \"bunches\",\n",
    "    \"time\": \"\",\n",
    "}\n",
    "\n",
    "# Create savefolder\n",
    "fsave = create_folder(\n",
    "    join(folder_general, sample, membrane, \"ID_%03d-%03d\" % (scan_id[0], scan_id[-1]))\n",
    ")\n",
    "\n",
    "# Setup xarray\n",
    "data = []\n",
    "\n",
    "# Loop over all scans\n",
    "for scan in tqdm(scans):\n",
    "    # Folder for loading\n",
    "    datafolder = join(basefolder, sample, scan)\n",
    "\n",
    "    # Loading experiment and background data\n",
    "    exp = preprocess_exp_OF(datafolder, keys=extra_keys, sort=False)\n",
    "    exp_bg = preprocess_exp_BG(datafolder, keys=extra_keys)\n",
    "\n",
    "    # Add wavelength\n",
    "    experimental_setup[\"lambda\"] = exp[\"wavelength\"][0] * 1e-9\n",
    "\n",
    "    # Normalize images\n",
    "    dark = np.mean(np.stack(exp_bg[\"images\"]), axis=0)\n",
    "    images = np.stack(exp.images) - dark\n",
    "    images = images / np.broadcast_to(np.array(exp[\"diode_sum_mean\"]), images.T.shape).T\n",
    "    images = np.mean(images, axis=0)\n",
    "\n",
    "    # Setup xarray dataset\n",
    "    data_scans = xr.Dataset()\n",
    "    data_scans[\"scan\"] = scan\n",
    "    data_scans[\"images\"] = xr.DataArray(images, dims=[\"y\", \"x\"])\n",
    "\n",
    "    for key in xr_keys:\n",
    "        data_scans[key] = exp[key].mean()\n",
    "\n",
    "    # Add to xarray list\n",
    "    data.append(data_scans)\n",
    "\n",
    "# Combine separate xarrays\n",
    "data = xr.concat(data, dim=\"scanid\")\n",
    "images = data[\"images\"].values\n",
    "im_mean = data[\"images\"].mean(\"scanid\").values\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedback plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot different variables over scan index\n",
    "scan_axis = \"IR_mean\"\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(data[scan_axis].values, \"-o\")\n",
    "ax.set_xlabel(\"Scan Index\")\n",
    "ax.set_ylabel(scan_axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot images\n",
    "fig, ax = cimshow(images)\n",
    "fig.set_size_inches(6, 6)\n",
    "ax.set_title(\"Images of scan\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw beamstop mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_mask = interactive.draw_polygon_mask(im_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take poly coordinates and mask from widget\n",
    "p_coord = poly_mask.coordinates\n",
    "mask = poly_mask.full_mask.astype(int)\n",
    "\n",
    "cimshow(mask)\n",
    "\n",
    "print(\"Mask coordinates: %s\" % p_coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_poly_coordinates(polyname):\n",
    "    if polyname == \"bs_cross\":\n",
    "        coord = [\n",
    "            (946.9258289571189, 901.9078818510652),\n",
    "            (-13.52166457167948, 915.628560330048),\n",
    "            (-8.033393180086364, 1107.7180590358075),\n",
    "            (944.1816932613224, 1099.4856519484179),\n",
    "            (946.9258289571189, 1988.5856173865054),\n",
    "            (945.4332858438797, 2042.780748713184),\n",
    "            (1134.4167167610876, 2056.6765892218023),\n",
    "            (1145.5333891679823, 1092.305257923697),\n",
    "            (2007.0755007023129, 1106.2010984323151),\n",
    "            (2067.2340362524137, 1100.0546685633194),\n",
    "            (2067.2340362524137, 910.7093055533562),\n",
    "            (1147.9485781605636, 902.4768984659665),\n",
    "            (1153.4368495521567, -38.761645192255855),\n",
    "            (955.8590794548038, -22.296831017476507),\n",
    "        ]\n",
    "\n",
    "    return coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which drawn masks do you want to load?\n",
    "polygon_names = [\"bs_cross\"]\n",
    "mask = load_poly_masks(polygon_names, images[0].shape)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5), sharex=True, sharey=True)\n",
    "mi, ma = np.percentile(im_mean, [1, 99])\n",
    "ax[0].imshow(im_mean * (1 - mask), vmin=mi, vmax=ma)\n",
    "ax[0].set_title(\"(1-mask)\")\n",
    "ax[1].imshow(im_mean * mask, vmin=mi, vmax=ma)\n",
    "ax[1].set_title(\"mask\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic widget to find center\n",
    "\n",
    "Try to **align** the circles to the **center of the scattering pattern**. Care! Position of beamstop might be misleading and not represent the actual center of the hologram. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set center position via widget\n",
    "ic = interactive.InteractiveCenter(images[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get center positions\n",
    "center = [ic.c0, ic.c1]\n",
    "print(f\"Center:\", center)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Azimuthal integrator widget for finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup azimuthal integrator for virtual geometry\n",
    "ai = interactive.AzimuthalIntegrator(\n",
    "    dist=experimental_setup[\"ccd_dist\"],\n",
    "    detector=detector,\n",
    "    wavelength=experimental_setup[\"lambda\"],\n",
    "    poni1=center[0]\n",
    "    * experimental_setup[\"px_size\"]\n",
    "    * experimental_setup[\"binning\"],  # y (vertical)\n",
    "    poni2=center[1]\n",
    "    * experimental_setup[\"px_size\"]\n",
    "    * experimental_setup[\"binning\"],  # x (horizontal)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting to find  relevant q range\n",
    "I_t, q_t, phi_t = ai.integrate2d(\n",
    "    im_mean,\n",
    "    200,\n",
    "    radial_range=(0, 0.05),\n",
    "    unit=\"q_nm^-1\",\n",
    "    correctSolidAngle=False,\n",
    "    dummy=np.nan,\n",
    "    mask=mask,\n",
    ")\n",
    "az2d = xr.DataArray(I_t, dims=(\"phi\", \"q\"), coords={\"q\": q_t, \"phi\": phi_t})\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots()\n",
    "mi, ma = np.nanpercentile(I_t, [1, 99])\n",
    "az2d.plot.imshow(ax=ax, vmin=mi, vmax=ma)\n",
    "plt.title(f\"Azimuthal integration\")\n",
    "\n",
    "# Vertical lines\n",
    "# q_lines = [0.025, 0.05]\n",
    "# for qt in q_lines:\n",
    "#    ax.axvline(qt, ymin=0, ymax=180, c=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aic = interactive.AzimuthalIntegrationCenter(\n",
    "    # np.log10(images[36] - np.min(images[36]) + 1),\n",
    "    im_mean,\n",
    "    ai,\n",
    "    c0=center[0],\n",
    "    c1=center[1],\n",
    "    mask=mask,\n",
    "    im_data_range=[1, 95],\n",
    "    radial_range=(0.005, 0.03),\n",
    "    qlines=[40, 60],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get center positions\n",
    "center = [aic.c0, aic.c1]\n",
    "print(f\"Center:\", center)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Azimuthal Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup final azimuthal integrator for virtual geometry\n",
    "ai = interactive.AzimuthalIntegrator(\n",
    "    dist=experimental_setup[\"ccd_dist\"],\n",
    "    detector=detector,\n",
    "    wavelength=experimental_setup[\"lambda\"],\n",
    "    poni1=center[0]\n",
    "    * experimental_setup[\"px_size\"]\n",
    "    * experimental_setup[\"binning\"],  # y (vertical)\n",
    "    poni2=center[1]\n",
    "    * experimental_setup[\"px_size\"]\n",
    "    * experimental_setup[\"binning\"],  # x (horizontal)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do 2d Azimuthal integration of all images and add to xarray\n",
    "list_i2d = []\n",
    "for im in tqdm(images):\n",
    "    i2d, q, chi = ai.integrate2d(im, 500, 90, dummy=np.nan, mask=mask)\n",
    "    list_i2d.append(i2d)\n",
    "\n",
    "# Add to xarray\n",
    "data[\"q\"] = q\n",
    "data[\"chi\"] = chi\n",
    "data[\"i2d\"] = xr.DataArray(list_i2d, dims=[\"scanid\", \"chi\", \"q\"])\n",
    "data = data.assign_attrs({\"center\": center})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select relevant chi-range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 2d and 1d azimuthal integration to estimate the relevant chi and q range\n",
    "# which image to show?\n",
    "idx = 3\n",
    "\n",
    "# Select chi-range\n",
    "# sel = (data.chi > -40) * (data.chi < 125) + (data.chi < -76) * (data.chi > 100)\n",
    "# data[\"i1d\"] = data.i2d.where(sel, drop=True).mean(\"chi\")\n",
    "data[\"i1d\"] = data.i2d.sum(\"chi\")\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(\n",
    "    2,\n",
    "    1,\n",
    "    figsize=(7, 7),\n",
    "    sharex=True,\n",
    ")\n",
    "mi, ma = np.nanpercentile(I_t, [0.1, 99])\n",
    "data[\"i2d\"][idx].plot.imshow(ax=ax[0], vmin=mi, vmax=ma)\n",
    "ax[0].set_title(f\"2d Azimuthal integration\")\n",
    "ax[0].grid()\n",
    "\n",
    "# Plot 1d azimuthal integration to estimate the relevant q-range\n",
    "ax[1].plot(data.q, data.i1d[idx])\n",
    "ax[1].set_yscale(\"log\")\n",
    "ax[1].set_title(\"1d Azimuthal Integration\")\n",
    "ax[1].grid()\n",
    "ax[1].set_ylabel(\"Integrated intensity\")\n",
    "ax[1].set_xlabel(\"q\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select relevant q-range and execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant q-range for averaging\n",
    "q0, q1 = 0.005, 0.04\n",
    "binning = False\n",
    "bins = []\n",
    "\n",
    "# Get SAXS from q-range\n",
    "sel = (data.q > q0) * (data.q < q1)\n",
    "data[\"saxs\"] = data.i1d.where(sel, drop=True).sum(\"q\")\n",
    "\n",
    "# Averaging of same scan axis values or binning\n",
    "if binning is True:\n",
    "    # Execute binning\n",
    "    data_bin = data.groupby_bins(scan_axis, bins).mean()\n",
    "\n",
    "    # Rename binned values, drop intervals as those cannot be save in h5\n",
    "    bin_scan_axis = scan_axis + \"_bins\"\n",
    "    data_bin = data_bin.swap_dims({bin_scan_axis: scan_axis})\n",
    "    data_bin = data_bin.drop(bin_scan_axis)\n",
    "else:\n",
    "    _, count = np.unique(data[scan_axis].values, return_counts=True)\n",
    "    if np.any(count > 1):\n",
    "        data_bin = data.groupby(scan_axis).mean()\n",
    "    else:\n",
    "        data_bin = data.copy()\n",
    "\n",
    "# Add AI mask\n",
    "data_bin[\"mask\"] = xr.DataArray(mask, dims=[\"y\", \"x\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1d AI & SAXS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all 1d AI\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "fig.suptitle(sample + \"_\" + membrane)\n",
    "for i in range(len(data_bin[\"scanid\"])):\n",
    "    ax[0].plot(\n",
    "        data_bin.q, data_bin[\"i1d\"][i].values, label=\"%0.1f ÂµJ\" % data_bin[\"IR_mean\"][i]\n",
    "    )\n",
    "ax[0].legend()\n",
    "ax[0].set_xlabel(\"q (nm$^{-1}$)\")\n",
    "ax[0].set_ylabel(\"intensity\")\n",
    "ax[0].grid()\n",
    "\n",
    "# Plot Integrated SAXS\n",
    "ax[1].plot(\n",
    "    data_bin[scan_axis].values, data_bin[\"saxs\"].values, label=\"Azimuthal Integration\"\n",
    "ax[1].set_xlabel(scan_axis)\n",
    "ax[1].set_ylabel(\"Integrated SAXS\")\n",
    "ax[1].grid()\n",
    "\n",
    "# Save fig\n",
    "fname = join(fsave, \"Fluence_%s_%s.png\" % (scan, USER))\n",
    "print(\"Saving: %s\" % fname)\n",
    "plt.savefig(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GIF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select roi for plotting\n",
    "\n",
    "How to use:\n",
    "1. Zoom into the image and adjust your FOV until you are satisfied.\n",
    "2. Save the axes coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = cimshow(data_bin[\"images\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes start and end of x and y axis\n",
    "x1, x2 = ax.get_xlim()\n",
    "y2, y1 = ax.get_ylim()\n",
    "roi = np.array([int(y1), int(y2), int(x1), int(x2)])\n",
    "roi_s = np.s_[roi[0] : roi[1], roi[2] : roi[3]]\n",
    "print(f\"Roi:\", roi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Find max and min considering all images\n",
    "allmin, allmax = np.nanpercentile(data_bin[\"i2d\"].values, [3, 97])\n",
    "print(\"Min: %d Max: %d\" % (allmin, allmax))\n",
    "\n",
    "# Create folder for gif single frames\n",
    "folder_gif = create_folder(join(fsave, \"Scan_%s-%s\" % (scans[0], scans[-1])))\n",
    "\n",
    "im_fnames = []\n",
    "for i in tqdm(range(len(data_bin[scan_axis].values))):\n",
    "    # Plot for averaged image\n",
    "    fig = plt.figure(figsize=(6.5, 10))\n",
    "    gs1 = gridspec.GridSpec(\n",
    "        2,\n",
    "        1,\n",
    "        figure=fig,\n",
    "        left=0.2,\n",
    "        bottom=0.05,\n",
    "        right=0.975,\n",
    "        top=1.1,\n",
    "        wspace=0,\n",
    "        hspace=0,\n",
    "        height_ratios=[3, 1],\n",
    "    )\n",
    "\n",
    "    ax0 = fig.add_subplot(gs1[0])\n",
    "    tmp = data_bin[\"images\"][i].values\n",
    "    m = ax0.imshow(tmp[roi_s], vmin=allmin, vmax=allmax)\n",
    "    ax0.set_title(\n",
    "        f\"%s:  %s = %.2f\"\n",
    "        % (data_bin[\"scan\"][i].values, scan_axis, data_bin[scan_axis].values[i])\n",
    "    )\n",
    "    plt.colorbar(m, ax=ax0, pad=0.045, location=\"bottom\")\n",
    "\n",
    "    ax1 = fig.add_subplot(gs1[1])\n",
    "    ax1.plot(data_bin[scan_axis].values, data_bin[\"saxs\"].values)\n",
    "    ax1.scatter(\n",
    "        data_bin[scan_axis].values[i], data_bin[\"saxs\"].values[i], 20, color=\"r\"\n",
    "    )\n",
    "    ax1.set_xlabel(scan_axis)\n",
    "    ax1.set_ylabel(\"Integrated intensity\")\n",
    "    ax1.grid()\n",
    "\n",
    "    # Save\n",
    "    fname = join(folder_gif, \"Fluence_%s-%s_%02d_%s.png\" % (scans[0], scans[-1], i, USER))\n",
    "    im_fnames.append(fname)\n",
    "    plt.savefig(fname)\n",
    "    plt.close()\n",
    "\n",
    "# Create gif for 1d AI\n",
    "var = [imageio.imread(file) for file in im_fnames]\n",
    "fname = f\"Fluence_%s-%s_%s.gif\" % (scans[0], scans[-1], USER)\n",
    "gif_path = join(fsave, fname)\n",
    "print(\"Saving gif:%s\" % gif_path)\n",
    "imageio.mimsave(gif_path, var, fps=2)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop images\n",
    "data_bin = data_bin.drop_vars([\"images\"])\n",
    "\n",
    "# Save log\n",
    "folder = join(fsave, \"Logs\")\n",
    "create_folder(folder)\n",
    "fname = join(folder, \"Log_SAXS_Scan_%s-%s_%s.nc\" % (scans[0], scans[-1], USER))\n",
    "\n",
    "print(f\"Saving:\", fname)\n",
    "data_bin.to_netcdf(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "179.1px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "300px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 493.85,
   "position": {
    "height": "40px",
    "left": "1580px",
    "right": "20px",
    "top": "120px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
