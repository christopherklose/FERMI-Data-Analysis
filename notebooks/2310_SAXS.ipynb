{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "\n",
    "Import python libraries as well as the self written FERMI library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from os.path import join, split\n",
    "from getpass import getuser\n",
    "from glob import glob\n",
    "from time import strftime\n",
    "from importlib import reload\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# data\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import h5py\n",
    "\n",
    "# Images\n",
    "import imageio\n",
    "from imageio import imread\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import NonUniformImage\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.path import Path\n",
    "\n",
    "# pyFAI\n",
    "import pyFAI\n",
    "\n",
    "pyFAI.disable_opencl = True  # get rid of annoying warning ;)\n",
    "from pyFAI.azimuthalIntegrator import AzimuthalIntegrator\n",
    "from pyFAI.detectors import Detector\n",
    "\n",
    "# Scipy\n",
    "from scipy.ndimage import median_filter\n",
    "\n",
    "# Self-written libraries\n",
    "sys.path.append(os.path.abspath(join(os.pardir,\"process_FERMI\")))\n",
    "import helper_functions as helper\n",
    "import mask_lib\n",
    "import process_FERMI as pf\n",
    "import interactive\n",
    "from interactive import cimshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# interactive plotting\n",
    "import ipywidgets\n",
    "\n",
    "%matplotlib widget\n",
    "plt.rcParams[\"figure.constrained_layout.use\"] = True\n",
    "\n",
    "# Auto formatting of cells\n",
    "#%load_ext jupyter_black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_exp(datafolder, extension, keys=None, sort=False, full_rate=False):\n",
    "    # Loading experiment data\n",
    "    print(\"Loading: %s\" % (datafolder + extension))\n",
    "    exp = pf.get_exp_dataframe(datafolder + extension, keys=keys)\n",
    "    for k in [\"xgm_UH\", \"xgm_SH\", \"diode_sum\"]:\n",
    "        exp[k + \"_sum\"] = exp[k].apply(np.sum)\n",
    "\n",
    "    exp[\"diode_sum_mean\"] = exp.diode_sum.apply(np.mean)\n",
    "    exp[\"diode_sum_sum\"] = exp.diode_sum.apply(np.sum)\n",
    "    exp[\"diode_sum_std\"] = exp.diode_sum.apply(np.std)\n",
    "    exp[\"IR_mean\"] = exp.IR.apply(np.mean)\n",
    "    exp[\"IR_std\"] = exp.IR.apply(np.std)\n",
    "    exp[\"magnet_mean\"] = exp.magnet.apply(np.mean)\n",
    "    exp[\"magnet_mean\"] = exp.magnet_mean.apply(np.round, args=(3,))\n",
    "    exp[\"bunchid\"] = exp.bunches.apply(lambda l: l[-1])\n",
    "\n",
    "    if sort is True:\n",
    "        exp = exp.sort_values(scan_axis)\n",
    "\n",
    "    load_images = []\n",
    "    for idx in range(len(exp[\"filename\"])):\n",
    "        try:\n",
    "            if full_rate:\n",
    "                temp = []\n",
    "                index = 0\n",
    "                load_images_full = pf.loadh5(\n",
    "                    exp[\"filename\"][idx], extra_keys=[\"alignz\", \"PAM/FQPDSum\"]\n",
    "                )[0].astype(\"float32\")\n",
    "                for i in range(len(load_images_full)):\n",
    "                    if np.max(load_images_full[i]) > 0:\n",
    "                        temp.append(load_images_full[i])\n",
    "                        index += 1\n",
    "                load_images.append(np.mean(temp, axis=0))\n",
    "                print(\"Skipped %d empty frames\" % (len(load_images_full) - index))\n",
    "            else:\n",
    "                load_images.append(\n",
    "                    pf.loadh5(\n",
    "                        exp[\"filename\"][idx], extra_keys=[\"alignz\", \"PAM/FQPDSum\"]\n",
    "                    )[0].astype(\"float32\")\n",
    "                )\n",
    "            print(\"Loaded %s\" % exp[\"filename\"][idx])\n",
    "        except:\n",
    "            print(\"Skipped %s\" % exp[\"filename\"][idx])\n",
    "\n",
    "    exp[\"images\"] = load_images\n",
    "\n",
    "    ## Loading image data\n",
    "    # exp[\"images\"] = [\n",
    "    #    np.mean(pf.loadh5(fname, extra_keys=[\"alignz\", \"PAM/FQPDSum\"])[0], axis=0)\n",
    "    #    # pf.loadh5(fname, extra_keys=[\"alignz\", \"PAM/FQPDSum\"])[0]\n",
    "    #    for fname in exp[\"filename\"]\n",
    "    # ]\n",
    "\n",
    "    return exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_false_images(images,filter_thres):\n",
    "    # Calc Monitoring parameter\n",
    "    image_mean = np.mean(images,axis = (-2,-1))\n",
    "    ensemble_mean = np.median(image_mean)\n",
    "    image_std = np.std(image_mean)\n",
    "\n",
    "    # Filter\n",
    "    valid = np.abs(image_mean-ensemble_mean) < filter_thres * image_std\n",
    "\n",
    "    # Plot filter condition\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(image_mean,'o-')\n",
    "    ax.grid()\n",
    "    ax.set_xlabel(\"Image Index\")\n",
    "    ax.set_ylabel(\"Image Mean\")\n",
    "    ax.set_title(\"Check for inconsistencies of the averaged intensity\")\n",
    "    ax.axhline(ensemble_mean,0,images.shape[0],color = 'g',linestyle = '--')\n",
    "    ax.axhline((ensemble_mean + filter_thres*image_std),0,images.shape[0],color = 'r',linestyle = '--')\n",
    "    ax.axhline((ensemble_mean - filter_thres*image_std),0,images.shape[0],color = 'r',linestyle = '--')\n",
    "    \n",
    "    return valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define basic folders\n",
    "BASEFOLDER = r\"/data/beamtimes/FERMI/2310_XPCS\"\n",
    "PROPOSAL = \"20224053\"\n",
    "USER = getuser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dict with most basic experimental parameter\n",
    "experimental_setup = {\n",
    "    \"px_size\": 11e-6,  # pixel_size of camera\n",
    "    \"binning\": 1,  # Camera binning\n",
    "}\n",
    "\n",
    "# Setup for azimuthal integrator\n",
    "detector = Detector(\n",
    "    experimental_setup[\"binning\"] * experimental_setup[\"px_size\"],\n",
    "    experimental_setup[\"binning\"] * experimental_setup[\"px_size\"],\n",
    ")\n",
    "\n",
    "# General saving folder\n",
    "folder_target = pf.create_folder(join(\"/data/export/cklose/2310_FERMI_Skyrmion\", \"Results\"))\n",
    "print(\"Output Folder: %s\" % folder_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Scan ids for loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define for loading\n",
    "sample = \"Sample54\"\n",
    "membrane = \"C6\"\n",
    "scan_id = 188\n",
    "scan = f\"%s_Slu_%03d\" % (membrane, scan_id)\n",
    "scan_axis = \"delay_ps\"\n",
    "full_rate = True\n",
    "\n",
    "# Folder for loading\n",
    "samplefolder = join(sample, scan)\n",
    "datafolder = join(BASEFOLDER, samplefolder)\n",
    "extra_keys = {\n",
    "    \"diode_sum\": \"PAM/FQPDSum\",\n",
    "    \"IR\": \"Laser/Energy1\",\n",
    "    \"magnet\": \"DPI/CoilWaveform\",\n",
    "    \"bunches\": \"bunches\",\n",
    "    \"time\": \"\",\n",
    "    \"samplex\": \"DPI/SampleX\",\n",
    "    \"sampley\": \"DPI/SampleY\",\n",
    "    \"ccdz\": \"DPI/CcdZ\",\n",
    "    \"global_delay\": \"Laser/DelayTotem\",\n",
    "}\n",
    "\n",
    "# Create savefolder\n",
    "fsave = helper.create_folder(join(folder_target, sample, membrane))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pumped images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loading experiment data\n",
    "extension = \"\"\n",
    "exp = preprocess_exp(datafolder, extension, keys=extra_keys)  # , full_rate=full_rate)\n",
    "\n",
    "# delay scan\n",
    "# Time-zero for delay scans\n",
    "t0 = 7.25\n",
    "exp[\"delay_ps\"] = 6.67 * (exp[\"delay\"] - t0)  # + (640 - exp[\"global_delay\"])\n",
    "exp = exp.sort_values(\"delay_ps\")\n",
    "\n",
    "# Add wavelength and distance\n",
    "experimental_setup[\"lambda\"] = exp[\"wavelength\"][0] * 1e-9\n",
    "experimental_setup[\"ccd_dist\"] = (exp[\"ccdz\"][0] + 50) * 1e-3\n",
    "\n",
    "\n",
    "images_pump = np.stack(exp[\"images\"])\n",
    "print(\"Data loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# What did you scan?\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.arange(len(exp)), exp[scan_axis], \"-o\")\n",
    "ax.set_xlabel(\"Index\")\n",
    "ax.set_ylabel(scan_axis)\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot images\n",
    "fig, ax = cimshow(images_pump)\n",
    "fig.set_size_inches(6, 6)\n",
    "ax.set_title(\"Pumped Images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter wrongly assigned frames, i.e., when shutter was not working correctly\n",
    "valid = filter_false_images(images_pump,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take only valid values\n",
    "exp = exp[valid]\n",
    "images_pump = np.stack(exp[\"images\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot images\n",
    "fig, ax = cimshow(images_pump)\n",
    "fig.set_size_inches(6, 6)\n",
    "ax.set_title(\"Pumped Images after filtering\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dark images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loading experiment data\n",
    "extension = \"_BG\"\n",
    "exp_bg = preprocess_exp(\n",
    "    datafolder, extension, keys=extra_keys\n",
    ")  # , full_rate=full_rate)\n",
    "exp_bg = exp_bg.sort_values(\"time\")\n",
    "\n",
    "dark = np.stack(exp_bg[\"images\"])\n",
    "print(\"Data loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot images\n",
    "fig, ax = cimshow(dark)\n",
    "fig.set_size_inches(6, 6)\n",
    "ax.set_title(\"Dark Images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter wrongly assigned frames, i.e., when shutter was not working correctly\n",
    "valid = filter_false_images(dark,2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take only valid values\n",
    "exp_bg = exp_bg[valid]\n",
    "dark = np.stack(exp_bg[\"images\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laser only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loading experiment data\n",
    "extension = \"_OL\"\n",
    "exp_ol = preprocess_exp(\n",
    "    datafolder, extension, keys=extra_keys\n",
    ")  # , full_rate=full_rate)\n",
    "exp_ol = exp_ol.sort_values(\"time\")\n",
    "\n",
    "dark_ol = np.stack(exp_ol[\"images\"])\n",
    "print(\"Data loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot images\n",
    "fig, ax = cimshow(dark_ol)\n",
    "fig.set_size_inches(6, 6)\n",
    "ax.set_title(\"Only Laser Images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter wrongly assigned frames, i.e., when shutter was not working correctly\n",
    "valid = filter_false_images(dark_ol,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take only valid values\n",
    "exp_ol = exp_ol[valid]\n",
    "dark_ol = np.stack(exp_ol[\"images\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FEL only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loading experiment data\n",
    "extension = \"_OF\"\n",
    "exp_of = preprocess_exp(\n",
    "    datafolder, extension, keys=extra_keys\n",
    ")  # , full_rate=full_rate)\n",
    "exp_of = exp_of.sort_values(\"time\")\n",
    "\n",
    "dark_of = np.stack(exp_of[\"images\"])\n",
    "print(\"Data loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot images\n",
    "fig, ax = cimshow(dark_of)\n",
    "fig.set_size_inches(6, 6)\n",
    "ax.set_title(\"Only FEL Images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter wrongly assigned frames, i.e., when shutter was not working correctly\n",
    "valid = filter_false_images(dark_of,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take only valid values\n",
    "exp_of = exp_of[valid]\n",
    "dark_of = np.stack(exp_of[\"images\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Which key to use for normalization?\n",
    "norm_key = \"diode_sum_sum\"\n",
    "filter_key = \"diode_sum_sum\"\n",
    "\n",
    "# Loop over images\n",
    "images = []\n",
    "for index, r in tqdm(exp.iterrows(), total=len(exp)):\n",
    "    # Find closest dark image in time series\n",
    "    idx = np.argmin(abs(r.time - exp_bg.time))\n",
    "    im_bg = exp_bg.iloc[idx][\"images\"]\n",
    "\n",
    "    # Find closest only laser image in time series\n",
    "    idx = np.argmin(abs(r.time - exp_ol.time))\n",
    "    im_ol = exp_ol.iloc[idx][\"images\"]\n",
    "\n",
    "    # Find closest only fel image in time series\n",
    "    idx = np.argmin(abs(r.time - exp_of.time))\n",
    "    im_of = exp_of.iloc[idx][\"images\"]\n",
    "\n",
    "    # Subtract background\n",
    "    #im = (r.images - im_ol) / r[norm_key]\n",
    "    #of_norm = (im_of - im_bg) / exp_of.iloc[idx][norm_key]\n",
    "    #im = im - of_norm\n",
    "\n",
    "    # Other option where background is subtracted first\n",
    "    im = r.images.copy()\n",
    "    im_ol = im_ol - im_bg\n",
    "    im_of = im_of - im_bg\n",
    "    im = im - im_bg\n",
    "\n",
    "    # Correction factor arising from shutter issues (not all images are pumped with laser, but considered for averaging)\n",
    "    shutter_correction = np.mean(im[1950:2025,750:1100])/np.mean(im_ol[1950:2025,750:1100]) #best option\n",
    "    #shutter_correction = np.mean(im[1900:2025,750:1100]*im_ol[1900:2025,750:1100])/np.mean(im_ol[1900:2025,750:1100]*im_ol[1900:2025,750:1100])\n",
    "    shutter_correction = 1\n",
    "    \n",
    "    im = (im - shutter_correction*im_ol)/ r[norm_key] - im_of / exp_of.iloc[idx][norm_key] \n",
    "\n",
    "    images.append(im)\n",
    "\n",
    "# Plot Intensity distribution\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(exp[scan_axis].values,np.mean(images,axis=(-2,-1)))\n",
    "ax.grid()\n",
    "ax.set_xlabel(str(scan_axis))\n",
    "ax.set_ylabel(\"Mean Intensity\")\n",
    "\n",
    "# Setup xarray\n",
    "data = xr.Dataset()\n",
    "data[\"images\"] = xr.DataArray(images, dims=[\"index\", \"y\", \"x\"])\n",
    "data[scan_axis] = xr.DataArray(exp[scan_axis], dims=[\"index\"])\n",
    "data[norm_key] = xr.DataArray(exp[norm_key], dims=[\"index\"])\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check filter for images with too high or low intensity\n",
    "exp_mean = data[norm_key].mean()\n",
    "exp_std = data[norm_key].std()\n",
    "filter_thres = 1.5\n",
    "\n",
    "# Plot filter condition\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(data[norm_key],'o')\n",
    "ax.set_xlabel(\"Image Index\")\n",
    "ax.set_ylabel(\"Image Mean\")\n",
    "ax.axhline(exp_mean,color = 'g',linestyle = '--')\n",
    "ax.axhline((exp_mean + filter_thres*exp_std),color = 'r',linestyle = '--')\n",
    "ax.axhline((exp_mean - filter_thres*exp_std),color = 'r',linestyle = '--')\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply filter\n",
    "data = data.where(np.abs(data[norm_key] - exp_mean) < filter_thres * exp_std, drop=True)\n",
    "images = data[\"images\"].values\n",
    "im_mean = data[\"images\"].mean(\"index\").values\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot images\n",
    "fig, ax = cimshow(images)\n",
    "fig.set_size_inches(6, 6)\n",
    "ax.set_title(\"Normalized % Filtered Images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw beamstop mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "poly_mask = interactive.draw_polygon_mask(np.mean(images[-10:],axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Take poly coordinates and mask from widget\n",
    "p_coord = poly_mask.get_vertice_coordinates()\n",
    "mask = poly_mask.full_mask.astype(int)\n",
    "\n",
    "cimshow(mask)\n",
    "\n",
    "print(\"Mask coordinates: %s\" % p_coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_poly_coordinates():\n",
    "    \"\"\"\n",
    "    Dictionary that stores polygon corner coordinates of all drawn masks\n",
    "    Example: How to add masks with name \"test\":\n",
    "    mask_coordinates[\"test\"] = copy coordinates from above\n",
    "    \"\"\"\n",
    "\n",
    "    # Setup dictonary\n",
    "    mask_coordinates = dict()\n",
    "\n",
    "    mask_coordinates[\"bs_cross\"] = [[(1500.1, -18.0), (1508.4, 552.7), (1508.4, 854.6), (1498.7, 972.9), (1455.0, 982.0), (737.3, 997.2), (-9.0, 1002.7), (-9.0, 1156.4), (309.3, 1150.9), (956.8, 1145.4), (1505.6, 1134.4), (1508.4, 1219.5), (1507.5, 1577.5), (1507.1, 2059.1), (1659.3, 2057.6), (1664.2, 1693.6), (1661.2, 1138.7), (2055.3, 1133.1), (2056.6, 987.1), (1664.9, 988.1), (1656.9, 588.6), (1658.4, 145.5), (1658.4, -32.2)]]\n",
    "    mask_coordinates[\"membranes\"] = [[(1266.7, 969.9), (1267.7, 1015.0), (1337.4, 1016.0), (1337.4, 963.0)], [(1365.8, 976.6), (1367.8, 1019.8), (1425.6, 1019.8), (1430.6, 968.8)], [(1452.1, 974.7), (1454.1, 1030.6), (1531.6, 1032.6), (1536.5, 971.7)], [(1608.1, 971.7), (1609.1, 1027.7), (1705.2, 1025.7), (1707.2, 969.8)], [(1713.1, 974.7), (1713.1, 1033.5), (1793.5, 1030.6), (1792.5, 969.8)], [(1805.3, 969.8), (1805.3, 1016.9), (1877.9, 1018.8), (1879.8, 965.9)], [(1902.4, 973.7), (1904.4, 1019.8), (1969.1, 1014.9), (1961.2, 968.8)],[(1264.1, 1146.0), (1267.5, 1195.2), (1335.6, 1193.7), (1332.5, 1144.5)]]\n",
    "    mask_coordinates[\"membranes_2\"] = [[(1823.2, 993.6), (1822.4, 1040.9), (1881.0, 1043.4), (1888.3, 1022.7), (1881.4, 989.6)], [(1909.8, 998.3), (1908.3, 1035.4), (1935.6, 1047.8), (1966.1, 1044.1), (1980.7, 1030.7), (1981.4, 1006.7), (1972.3, 992.1), (1926.8, 989.6)]]\n",
    "    return mask_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Which drawn masks do you want to load? (you can add multiple masks in list e.g. [\"bs_cross\",\"bs_bar_delayscans\"])\n",
    "polygon_names = [\"bs_cross\",\"membranes\"] \n",
    "mask = mask_lib.load_poly_masks(images[0].shape,load_poly_coordinates(),polygon_names)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5), sharex=True, sharey=True)\n",
    "mi, ma = np.percentile(im_mean, [1, 99])\n",
    "ax[0].imshow(im_mean * (1 - mask), vmin=mi, vmax=ma)\n",
    "ax[0].set_title(\"(1-mask)\")\n",
    "ax[1].imshow(im_mean * mask, vmin=mi, vmax=ma)\n",
    "ax[1].set_title(\"mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use widget to shift and expand or shrink the mask\n",
    "ss_mask = interactive.Shift_Scale_Mask(im_of, mask, shift=[0, 0], scale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take mask, shift and scaling from widget\n",
    "mask, mask_shift, mask_scale = ss_mask.get_mask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygon_names = [\"membranes_2\"] \n",
    "mask = mask + mask_lib.load_poly_masks(images[0].shape,load_poly_coordinates(),polygon_names)\n",
    "mask[mask>1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use widget to shift and expand or shrink the mask\n",
    "ss_mask = interactive.Shift_Scale_Mask(im_of, mask, shift=[0, 0], scale=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic widget to find center\n",
    "\n",
    "Try to **align** the circles to the **center of the scattering pattern**. Care! Position of beamstop might be misleading and not represent the actual center of the hologram. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set center position via widget\n",
    "ic = interactive.InteractiveCenter(np.mean(images[0:1]*(1-mask), axis=0),c0=1087,c1=1583,rBS=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get center positions\n",
    "center = [ic.c0, ic.c1]\n",
    "print(f\"Center:\", center)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Azimuthal integrator widget for finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup azimuthal integrator for virtual geometry\n",
    "ai = interactive.AzimuthalIntegrator(\n",
    "    dist=experimental_setup[\"ccd_dist\"],\n",
    "    detector=detector,\n",
    "    wavelength=experimental_setup[\"lambda\"],\n",
    "    poni1=center[0]\n",
    "    * experimental_setup[\"px_size\"]\n",
    "    * experimental_setup[\"binning\"],  # y (vertical)\n",
    "    poni2=center[1]\n",
    "    * experimental_setup[\"px_size\"]\n",
    "    * experimental_setup[\"binning\"],  # x (horizontal)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plotting to find  relevant q range\n",
    "I_t, q_t, phi_t = ai.integrate2d(\n",
    "    images[-1],\n",
    "    200,\n",
    "    radial_range=(0, 0.1),\n",
    "    unit=\"q_nm^-1\",\n",
    "    correctSolidAngle=False,\n",
    "    dummy=np.nan,\n",
    "    mask=mask,\n",
    "    method=\"bbox\"\n",
    ")\n",
    "az2d = xr.DataArray(I_t, dims=(\"phi\", \"q\"), coords={\"q\": q_t, \"phi\": phi_t})\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots()\n",
    "mi, ma = np.nanpercentile(I_t, [1, 95])\n",
    "az2d.plot.imshow(ax=ax, vmin=mi, vmax=ma)\n",
    "plt.title(f\"Azimuthal integration\")\n",
    "\n",
    "# Vertical lines\n",
    "# q_lines = [0.025, 0.05]\n",
    "# for qt in q_lines:\n",
    "#    ax.axvline(qt, ymin=0, ymax=180, c=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aic = interactive.AzimuthalIntegrationCenter(\n",
    "    # np.log10(images[36] - np.min(images[36]) + 1),\n",
    "    np.mean(images[-10:], axis=0),\n",
    "    ai,\n",
    "    c0=center[0],\n",
    "    c1=center[1],\n",
    "    mask=mask,\n",
    "    im_data_range=[1, 95],\n",
    "    radial_range=(0.003, 0.07),\n",
    "    qlines=[40, 60],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get center positions\n",
    "center = [aic.c0, aic.c1]\n",
    "print(f\"Center:\", center)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Azimuthal Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup final azimuthal integrator for virtual geometry\n",
    "ai = interactive.AzimuthalIntegrator(\n",
    "    dist=experimental_setup[\"ccd_dist\"],\n",
    "    detector=detector,\n",
    "    wavelength=experimental_setup[\"lambda\"],\n",
    "    poni1=center[0]\n",
    "    * experimental_setup[\"px_size\"]\n",
    "    * experimental_setup[\"binning\"],  # y (vertical)\n",
    "    poni2=center[1]\n",
    "    * experimental_setup[\"px_size\"]\n",
    "    * experimental_setup[\"binning\"],  # x (horizontal)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Do 2d Azimuthal integration of all images and add to xarray\n",
    "list_i2d = []\n",
    "for im in tqdm(data[\"images\"].values):\n",
    "    i2d, q, chi = ai.integrate2d(im, 500, 90, dummy=np.nan, mask=mask,method=\"bbox\")\n",
    "    list_i2d.append(i2d)\n",
    "\n",
    "# Setup xarray\n",
    "data[\"q\"] = q\n",
    "data[\"chi\"] = chi\n",
    "data[\"i2d\"] = xr.DataArray(list_i2d, dims=[\"index\", \"chi\", \"q\"])\n",
    "data = data.assign_attrs({\"center\": center})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select relevant chi-range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot 2d and 1d azimuthal integration to estimate the relevant chi and q range\n",
    "# which image to show?\n",
    "idx = -1\n",
    "\n",
    "# Select chi-range\n",
    "# Which chi-mode? (all,hetero,homo)\n",
    "chi_mode = \"all\"\n",
    "\n",
    "# Select chi-range\n",
    "if chi_mode == \"all\":\n",
    "    sel_chi = (data.chi <= 180) * (data.chi >= -180)\n",
    "    data[\"i1d\"] = data.i2d.where(sel_chi, drop=True).mean(\"chi\")\n",
    "elif chi_mode == \"hetero\":\n",
    "    sel_chi = (data.chi < 180) * (data.chi > 95)\n",
    "    data[\"i1d\"] = data.i2d.where(sel_chi, drop=True).mean(\"chi\")\n",
    "elif chi_mode == \"homo\":\n",
    "    sel_chi = (data.chi <= -95) * (data.chi >= -180) + (data.chi <= 90) * (\n",
    "        data.chi >= 5\n",
    "    )\n",
    "    data[\"i1d\"] = data.i2d.where(sel_chi, drop=True).mean(\"chi\")\n",
    "elif chi_mode == \"other\":\n",
    "    sel_chi = (data.chi <= 150) * (data.chi >= 40)\n",
    "    data[\"i1d\"] = data.i2d.where(sel_chi, drop=True).mean(\"chi\")\n",
    "# Plot\n",
    "fig, ax = plt.subplots(\n",
    "    2,\n",
    "    1,\n",
    "    figsize=(8, 8),\n",
    "    sharex=True,\n",
    ")\n",
    "mi, ma = np.nanpercentile(I_t, [0.1, 90])\n",
    "data[\"i2d\"][idx].plot.imshow(ax=ax[0], vmin=mi, vmax=ma)\n",
    "ax[0].set_title(f\"2d Azimuthal integration\")\n",
    "ax[0].grid()\n",
    "\n",
    "# Plot 1d azimuthal integration to estimate the relevant q-range\n",
    "ax[1].plot(data.q, data.i1d[idx])\n",
    "ax[1].set_yscale(\"log\")\n",
    "ax[1].set_title(\"1d Azimuthal Integration\")\n",
    "ax[1].grid()\n",
    "ax[1].set_ylabel(\"Integrated intensity\")\n",
    "ax[1].set_xlabel(\"q\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select relevant q-range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select relevant q-range for averaging\n",
    "q0, q1 = 0.005, 0.1\n",
    "binning = False\n",
    "bins = []\n",
    "\n",
    "# Get SAXS from q-range\n",
    "sel = (data.q > q0) * (data.q < q1)\n",
    "data[\"saxs\"] = data.i1d.where(sel, drop=True).mean(\"q\")\n",
    "\n",
    "# Averaging of same scan axis values or binning\n",
    "if binning is True:\n",
    "    # Execute binning\n",
    "    data_bin = data.groupby_bins(scan_axis, bins).mean()\n",
    "\n",
    "    # Rename binned values, drop intervals as those cannot be save in h5\n",
    "    bin_scan_axis = scan_axis + \"_bins\"\n",
    "    data_bin = data_bin.swap_dims({bin_scan_axis: scan_axis})\n",
    "    data_bin = data_bin.drop(bin_scan_axis)\n",
    "else:\n",
    "    _, count = np.unique(data[scan_axis].values, return_counts=True)\n",
    "    if np.any(count > 1):\n",
    "        data_bin = data.groupby(scan_axis).mean()\n",
    "    else:\n",
    "        data_bin = data.swap_dims({\"index\": scan_axis})\n",
    "\n",
    "# To create log plot\n",
    "data_bin[\"i1dlog\"] = np.log10(data_bin[\"i1d\"]+ 1)\n",
    "\n",
    "# Add scan identifier\n",
    "data_bin[\"scan\"] = scan\n",
    "\n",
    "# Add AI mask\n",
    "data_bin[\"mask\"] = xr.DataArray(mask, dims=[\"y\", \"x\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot I(q,t) and integrated intensity\n",
    "fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(6, 4.5), sharex=True)\n",
    "vmin, vmax = data_bin[\"i1d\"].min(), data_bin[\"i1d\"].max()\n",
    "vmin, vmax = np.percentile(data_bin[\"i1d\"], [1, 99])\n",
    "data_bin[\"i1d\"].plot.contourf(\n",
    "    x=\"delay_ps\",\n",
    "    y=\"q\",\n",
    "    ax=ax[0],\n",
    "    cmap=\"viridis\",\n",
    "    add_colorbar=False,\n",
    "    vmin=vmin,\n",
    "    vmax=vmax,\n",
    "    levels=100,\n",
    "    ylim = [q0,q1]\n",
    ")\n",
    "\n",
    "ax[1].plot(data_bin[\"delay_ps\"], data_bin[\"saxs\"], \"o-\")\n",
    "ax[1].grid()\n",
    "ax[0].set_xlabel(\"\")\n",
    "ax[1].set_ylabel(\"total scattered intensity\")\n",
    "ax[1].set_xlabel(\"delay (ps)\")\n",
    "\n",
    "ir = exp[\"IR_mean\"].mean()\n",
    "mag = exp.magnet[0][0]\n",
    "fig.suptitle(f\"{samplefolder}: IR: {ir:.2f} µJ, magnet: {mag:.2f} A\")\n",
    "\n",
    "fname = join(fsave, \"SAXS_%s_qdelay_%s.png\" % (scan, USER))\n",
    "print(\"Saving: %s\" % fname)\n",
    "plt.savefig(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gif\n",
    "\n",
    "## Select roi for plotting\n",
    "\n",
    "How to use:\n",
    "1. Zoom into the image and adjust your FOV until you are satisfied.\n",
    "2. Save the axes coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = cimshow(data_bin[\"images\"].values*(1-mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Takes start and end of x and y axis\n",
    "x1, x2 = ax.get_xlim()\n",
    "y2, y1 = ax.get_ylim()\n",
    "roi = np.array([int(y1), int(y2), int(x1), int(x2)])\n",
    "roi_s = np.s_[roi[0] : roi[1], roi[2] : roi[3]]\n",
    "print(f\"Roi:\", roi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Find max and min considering all images\n",
    "allmin, allmax = np.nanpercentile(data_bin[\"i2d\"].values, [10, 99])\n",
    "print(\"Min: %d Max: %d\" % (allmin, allmax))\n",
    "\n",
    "# Create folder for gif single frames\n",
    "folder_gif = helper.create_folder(join(fsave, \"Scan_%s\" % scan))\n",
    "\n",
    "im_fnames = []\n",
    "for i in tqdm(range(len(data_bin[scan_axis].values))):\n",
    "    # Plot for averaged image\n",
    "    fig = plt.figure(figsize=(6, 10))\n",
    "    gs1 = gridspec.GridSpec(\n",
    "        4,\n",
    "        1,\n",
    "        figure=fig,\n",
    "        left=0.2,\n",
    "        bottom=0.05,\n",
    "        right=0.975,\n",
    "        top=1.1,\n",
    "        wspace=0,\n",
    "        hspace=0,\n",
    "        height_ratios=[6, 1, 2, 1],\n",
    "    )\n",
    "\n",
    "    # Plot image roi\n",
    "    ax0 = fig.add_subplot(gs1[0])\n",
    "    ir = exp[\"IR_mean\"].mean()\n",
    "    mag = exp.magnet[0][0]  # exp.magnet.mean()\n",
    "    ax0.set_title(\n",
    "        f\"{scan}: IR: {ir:.1f} µJ, magnet: {mag:.2f} A, delay: {data_bin[scan_axis].values[i]:.0f} ps\",\n",
    "        fontsize=10,\n",
    "    )\n",
    "    tmp = data_bin[\"images\"][i].values\n",
    "    m = ax0.imshow(tmp[roi_s]*(1-mask[roi_s]), vmin=allmin, vmax=allmax)\n",
    "    plt.colorbar(m, ax=ax0, pad=0.045, location=\"bottom\")\n",
    "\n",
    "    # Plot 1d azimuthal integration\n",
    "    ax1 = fig.add_subplot(gs1[1])\n",
    "    tmp = data_bin.i1d[i]\n",
    "    ax1.plot(data_bin.q, tmp)\n",
    "    ax1.set_xlabel(\"q\")\n",
    "    ax1.set_ylabel(\"Mean Intensity\")\n",
    "    ax1.set_xlim([q0, q1])\n",
    "    ax1.set_ylim([allmin, allmax])\n",
    "    #ax1.set_yscale(\"log\")\n",
    "    ax1.grid()\n",
    "\n",
    "    \n",
    "    ax2 = fig.add_subplot(gs1[2])\n",
    "    vmin, vmax = np.nanpercentile(data_bin[\"i1d\"], [.5, 99.5])\n",
    "    data_bin[\"i1d\"].plot.contourf(\n",
    "        x=scan_axis,\n",
    "        y=\"q\",\n",
    "        ax=ax2,\n",
    "        cmap=\"viridis\",\n",
    "        add_colorbar=False,\n",
    "        vmin=vmin,\n",
    "        vmax=vmax,\n",
    "        levels=200,\n",
    "        ylim = [q0,q1]\n",
    "    )\n",
    "    ax2.vlines(data_bin[scan_axis].values[i], q0, q1,'r')\n",
    "    ax2.hlines(q0, data_bin[scan_axis].min(),data_bin[scan_axis].max(),'w',linestyles='dashed')\n",
    "    ax2.hlines(q1, data_bin[scan_axis].min(),data_bin[scan_axis].max(),'w',linestyles='dashed')\n",
    "\n",
    "    # Plot SAXS Intensity\n",
    "    ax3 = fig.add_subplot(gs1[3])\n",
    "    ax3.plot(data_bin[scan_axis].values, data_bin[\"saxs\"].values)\n",
    "    ax3.scatter(data_bin[scan_axis].values[i], data_bin[\"saxs\"].values[i], 20, color=\"r\")\n",
    "    ax3.set_xlabel(scan_axis)\n",
    "    ax3.set_ylabel(\"Mean intensity\")\n",
    "    ax3.grid()\n",
    "    ax3.set_xlim(data_bin[scan_axis].min(),data_bin[scan_axis].max())\n",
    "\n",
    "    # Save\n",
    "    fname = join(folder_gif, \"SAXS_%s_%03d_%s.png\" % (scan, i, USER))\n",
    "    im_fnames.append(fname)\n",
    "    plt.savefig(fname)\n",
    "    plt.close()\n",
    "\n",
    "# Create gif for 1d AI\n",
    "fname = f\"SAXS_%s_%s.gif\" % (scan, USER)\n",
    "gif_path = join(fsave, fname)\n",
    "print(\"Saving gif:%s\" % gif_path)\n",
    "helper.create_gif(im_fnames,gif_path,fps=2)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop images\n",
    "data_bin2 = data_bin.drop_vars([\"images\"])\n",
    "\n",
    "# Save log\n",
    "folder = join(fsave, \"Logs\")\n",
    "helper.create_folder(folder)\n",
    "fname = join(folder, \"Log_SAXS_Scan_%03d_%s.nc\" % (scan_id, USER))\n",
    "\n",
    "print(f\"Saving:\", fname)\n",
    "data_bin2.to_netcdf(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:klose-2309-cuda_ck]",
   "language": "python",
   "name": "conda-env-klose-2309-cuda_ck-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "179.1px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "300px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 493.85,
   "position": {
    "height": "40px",
    "left": "1580px",
    "right": "20px",
    "top": "120px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
