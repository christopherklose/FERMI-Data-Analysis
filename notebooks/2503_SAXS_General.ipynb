{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Imports\n",
    "\n",
    "Import python libraries as well as the self written FERMI library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from os.path import join, split\n",
    "from getpass import getuser\n",
    "from glob import glob\n",
    "from time import strftime\n",
    "from tqdm.auto import tqdm\n",
    "from importlib import reload\n",
    "\n",
    "# Data\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import h5py\n",
    "\n",
    "# Images\n",
    "import imageio\n",
    "from imageio import imread\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import NonUniformImage\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.path import Path\n",
    "\n",
    "# pyFAI\n",
    "import pyFAI\n",
    "from pyFAI.azimuthalIntegrator import AzimuthalIntegrator\n",
    "from pyFAI.detectors import Detector\n",
    "\n",
    "# Self-written libraries\n",
    "sys.path.append(os.path.abspath(join(os.pardir,\"process_FERMI\")))\n",
    "import helper_functions as helper\n",
    "import mask_lib\n",
    "import process_FERMI as pf\n",
    "import interactive\n",
    "from interactive import cimshow\n",
    "\n",
    "plt.rcParams[\"figure.constrained_layout.use\"] = True  # replaces plt.tight_layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# interactive plotting\n",
    "import ipywidgets\n",
    "\n",
    "%matplotlib widget\n",
    "plt.rcParams[\"figure.constrained_layout.use\"] = True\n",
    "\n",
    "# Auto formatting of cells\n",
    "#load_ext jupyter_black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_exp(datafolder, extension, keys=None, sort=False, full_rate=False):\n",
    "    \"\"\"\n",
    "    Loads and preprocesses experiment data from a specified datafolder and file extensions (Dark, Only-Laser, Only-FEL, etc).\n",
    "    \n",
    "    Parameters:\n",
    "        datafolder (str): Path to the folder containing the data.\n",
    "        extension (str): File extension of the data files. (Dark, Only-Laser, Only-FEL, etc. ...)\n",
    "        keys (list, optional): Specific HDF5-keys to additionaly extract from the data. Defaults to None.\n",
    "        sort (bool, optional): Whether to sort the data based on a scan axis. Defaults to False.\n",
    "        full_rate (bool, optional): If True, filters out empty frames before averaging images. Defaults to False.\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: Preprocessed experiment data with computed statistics and loaded images.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    # Loading experiment data\n",
    "    print(\"Loading: %s\" % (datafolder + extension))\n",
    "    exp = pf.get_exp_dataframe(datafolder + extension, keys=keys)\n",
    "    for k in [\"xgm_UH\", \"xgm_SH\", \"diode_sum\"]:\n",
    "        exp[k + \"_sum\"] = exp[k].apply(np.sum)\n",
    "\n",
    "    exp[\"diode_sum_mean\"] = exp.diode_sum.apply(np.mean)\n",
    "    exp[\"diode_sum_sum\"] = exp.diode_sum.apply(np.sum)\n",
    "    exp[\"diode_sum_std\"] = exp.diode_sum.apply(np.std)\n",
    "    exp[\"IR_mean\"] = exp.IR.apply(np.mean)\n",
    "    exp[\"IR_std\"] = exp.IR.apply(np.std)\n",
    "    exp[\"magnet_mean\"] = exp.magnet.apply(np.mean)\n",
    "    exp[\"magnet_mean\"] = exp.magnet_mean.apply(np.round, args=(3,))\n",
    "    exp[\"bunchid\"] = exp.bunches.apply(lambda l: l[-1])\n",
    "\n",
    "    if sort is True:\n",
    "        exp = exp.sort_values(scan_axis)\n",
    "\n",
    "    load_images = []\n",
    "    for idx in range(len(exp[\"filename\"])):\n",
    "        try:\n",
    "            if full_rate:\n",
    "                temp = []\n",
    "                index = 0\n",
    "                load_images_full = pf.loadh5(\n",
    "                    exp[\"filename\"][idx], extra_keys=[\"DPI/AlignZm\", \"PAM/FQPDSum\"] \n",
    "                )[0].astype(\"float32\")\n",
    "                for i in range(len(load_images_full)):\n",
    "                    if np.max(load_images_full[i]) > 0:\n",
    "                        temp.append(load_images_full[i])\n",
    "                        index += 1\n",
    "                load_images.append(np.mean(temp, axis=0))\n",
    "                print(\"Skipped %d empty frames\" % (len(load_images_full) - index))\n",
    "            else:\n",
    "                load_images.append(\n",
    "                    pf.loadh5(\n",
    "                        exp[\"filename\"][idx], extra_keys=[ \"DPI/AlignZm\",\"PAM/FQPDSum\"] \n",
    "                    )[0].astype(\"float32\")\n",
    "                )\n",
    "            print(\"Loaded %s\" % exp[\"filename\"][idx])\n",
    "        except:\n",
    "            print(\"Skipped %s\" % exp[\"filename\"][idx])\n",
    "\n",
    "    exp[\"images\"] = load_images\n",
    "    \n",
    "    return exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_false_images(images,filter_thres):\n",
    "    \"\"\"\n",
    "    Identifies and filters out inconsistent images based on intensity deviations.\n",
    "    \n",
    "    This function computes the mean intensity of each image, compares it to the \n",
    "    ensemble median, and filters out images that deviate beyond a threshold \n",
    "    determined by the standard deviation.\n",
    "    \n",
    "    Parameters:\n",
    "        images (numpy.ndarray): Array of images to be analyzed.\n",
    "        filter_thres (float): Threshold for filtering, defining the acceptable \n",
    "                              deviation from the median intensity.\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: Boolean array indicating valid (True) and filtered (False) images.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calc Monitoring parameter\n",
    "    image_mean = np.nanmean(images,axis = (-2,-1))\n",
    "    ensemble_mean = np.nanmedian(image_mean)\n",
    "    image_std = np.nanstd(image_mean)\n",
    "\n",
    "    # Filter\n",
    "    valid = np.abs(image_mean-ensemble_mean) < filter_thres * image_std\n",
    "\n",
    "    # Plot filter condition\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(image_mean,'o-')\n",
    "    ax.grid()\n",
    "    ax.set_xlabel(\"Image Index\")\n",
    "    ax.set_ylabel(\"Image Mean\")\n",
    "    ax.set_title(\"Check for inconsistencies of the averaged intensity\")\n",
    "    ax.axhline(ensemble_mean,0,images.shape[0],color = 'g',linestyle = '--')\n",
    "    ax.axhline((ensemble_mean + filter_thres*image_std),0,images.shape[0],color = 'r',linestyle = '--')\n",
    "    ax.axhline((ensemble_mean - filter_thres*image_std),0,images.shape[0],color = 'r',linestyle = '--')\n",
    "    \n",
    "    return valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define basic folders\n",
    "BASEFOLDER = r\"/data/beamtimes/FERMI/2310_XPCS\"\n",
    "PROPOSAL = \"20224053\"\n",
    "USER = getuser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dict with most basic experimental parameter\n",
    "experimental_setup = {\n",
    "    \"px_size\": 11e-6,  # pixel_size of camera\n",
    "    \"binning\": 1,  # Camera binning\n",
    "}\n",
    "\n",
    "# Setup for azimuthal integrator\n",
    "detector = Detector(\n",
    "    experimental_setup[\"binning\"] * experimental_setup[\"px_size\"],\n",
    "    experimental_setup[\"binning\"] * experimental_setup[\"px_size\"],\n",
    ")\n",
    "\n",
    "# General saving folder\n",
    "folder_target = pf.create_folder(join(\"/data/beamtimes/FERMI/2503_temp_chiral/results\", \"Ana_Log\"))\n",
    "print(\"Output Folder: %s\" % folder_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define for loading\n",
    "sample = \"Sample54\"\n",
    "membrane = \"I7\"  # \"E8_PumpedHyst\"  # \"I2_PumpedHyst\"\n",
    "scan_id = 6\n",
    "scan = f\"%s_%03d\" % (membrane, scan_id)\n",
    "\n",
    "# Is it pumped hysteresis, or static hysteresis?\n",
    "pumped_hysteresis = False\n",
    "\n",
    "# Recorded with full rate?\n",
    "full_rate = False\n",
    "\n",
    "if pumped_hysteresis:\n",
    "    # Use last nominal value of the magnet waveform\n",
    "    scan_axis = \"magnet_last\"\n",
    "    # Use FEL+IR as image\n",
    "    extension = \"\"\n",
    "else:\n",
    "    # Use averaged magnet value\n",
    "    scan_axis = \"magnet_mean\"\n",
    "    # Use OF as image\n",
    "    extension = \"_OF\"\n",
    "\n",
    "# Folder for loading\n",
    "samplefolder = join(sample, scan)\n",
    "datafolder = join(BASEFOLDER, samplefolder)\n",
    "extra_keys = {\n",
    "    \"diode_sum\": \"PAM/FQPDSum\",\n",
    "    \"IR\": \"Laser/Energy1\",\n",
    "    \"magnet\": \"DPI/CoilCurrent\",\n",
    "    \"magnet_waveform\": \"DPI/CoilWaveform\",\n",
    "    \"bunches\": \"bunches\",\n",
    "    \"time\": \"\",\n",
    "    \"samplex\": \"DPI/SampleX\",\n",
    "    \"sampley\": \"DPI/SampleY\",\n",
    "    \"ccdz\": \"DPI/CcdZ\",\n",
    "}\n",
    "\n",
    "# Create savefolder\n",
    "fsave = pf.create_folder(join(folder_target, sample, membrane))\n",
    "\n",
    "# Loading experiment data\n",
    "#exp = pf.get_exp_dataframe(datafolder, \"_OF\", keys=extra_keys)\n",
    "exp = preprocess_exp(datafolder, extension, keys=extra_keys)\n",
    "#exp_Saturated = preprocess_exp(datafolder, \"_Saturated\", keys=extra_keys)\n",
    "\n",
    "# Add wavelength and distance\n",
    "experimental_setup[\"lambda\"] = exp[\"wavelength\"][0] * 1e-9\n",
    "experimental_setup[\"ccd_dist\"] = (exp[\"ccdz\"][0] + 50) * 1e-3\n",
    "\n",
    "print(\"Data loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# What did you scan?\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.arange(len(exp)), exp[scan_axis], \"-o\")\n",
    "ax.set_xlabel(\"Index\")\n",
    "ax.set_ylabel(scan_axis)\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = cimshow(np.stack(exp.images))\n",
    "ax.set_title(\"Image Slideshow viewer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dark images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loading experiment data\n",
    "scan_BG = f\"%s_%03d\" % (membrane, scan_id)\n",
    "samplefolder_BG = join(sample, scan_BG)\n",
    "datafolder_BG = join(BASEFOLDER, samplefolder_BG)\n",
    "\n",
    "extension = \"_BG\"\n",
    "\n",
    "exp_bg = preprocess_exp(datafolder_BG, extension, keys=extra_keys)\n",
    "exp_bg = exp_bg.sort_values(\"time\")\n",
    "\n",
    "if pumped_hysteresis:\n",
    "    dark = np.stack(exp_bg[\"images\"])\n",
    "else:\n",
    "    dark = np.mean(np.stack(exp_bg[\"images\"]), axis=0)\n",
    "\n",
    "print(\"Data loaded!\")\n",
    "\n",
    "# Plot images\n",
    "fig, ax = cimshow(dark)\n",
    "fig.set_size_inches(6, 6)\n",
    "ax.set_title(\"Dark Image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laser only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if pumped_hysteresis:\n",
    "    # Loading experiment data\n",
    "    extension = \"_OL\"\n",
    "    exp_ol = preprocess_exp(datafolder, extension, keys=extra_keys)\n",
    "    exp_ol = exp_ol.sort_values(\"time\")\n",
    "\n",
    "    dark_ol = np.stack(exp_ol[\"images\"])\n",
    "    print(\"Data loaded!\")\n",
    "\n",
    "    # Plot images\n",
    "    fig, ax = cimshow(dark_ol)\n",
    "    fig.set_size_inches(6, 6)\n",
    "    ax.set_title(\"Only Laser Images\")\n",
    "else:\n",
    "    print(\"Not executed for static hysteresis!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEL only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if pumped_hysteresis:\n",
    "    # Loading experiment data\n",
    "    extension = \"_OF\"\n",
    "    exp_of = preprocess_exp(datafolder, extension, keys=extra_keys)\n",
    "    exp_of = exp_of.sort_values(\"time\")\n",
    "\n",
    "    dark_of = np.stack(exp_of[\"images\"])\n",
    "    print(\"Data loaded!\")\n",
    "\n",
    "    # Plot images\n",
    "    fig, ax = cimshow(dark_of)\n",
    "    fig.set_size_inches(6, 6)\n",
    "    ax.set_title(\"Only FEL Images\")\n",
    "else:\n",
    "    print(\"Not executed for static hysteresis!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtract dark images (for dynamic hysteresis also OL, OF) and normalize images to I0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Incident intensity\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.arange(len(exp)), exp[\"diode_sum_sum\"])\n",
    "ax.set_xlabel(\"Image Index\")\n",
    "ax.set_ylabel(\"Incident Intensity (a.u.)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Which key to use for normalization?\n",
    "norm_key = \"diode_sum_sum\"\n",
    "filter_key = \"diode_sum_sum\"\n",
    "\n",
    "if pumped_hysteresis:\n",
    "    # Loop over images\n",
    "    images = []\n",
    "    images_of = []\n",
    "    for index, r in tqdm(exp.iterrows(), total=len(exp)):\n",
    "        # Find closest dark image in time series\n",
    "        idx = np.argmin(abs(r.time - exp_bg.time))\n",
    "        im_bg = exp_bg.iloc[idx][\"images\"]\n",
    "\n",
    "        # Find closest only laser image in time series\n",
    "        idx = np.argmin(abs(r.time - exp_ol.time))\n",
    "        im_ol = exp_ol.iloc[idx][\"images\"]\n",
    "\n",
    "        # Find closest only fel image in time series\n",
    "        idx = np.argmin(abs(r.time - exp_of.time))\n",
    "        im_of = exp_of.iloc[idx][\"images\"]\n",
    "\n",
    "        # Subtract background\n",
    "        im = (r.images - im_ol) / r[norm_key]\n",
    "        of_norm = (im_of - im_bg) / exp_of.iloc[idx][norm_key]\n",
    "        im = im - of_norm\n",
    "\n",
    "        images.append(im)\n",
    "        images_of.append(of_norm)\n",
    "else:\n",
    "    images = np.stack(exp.images) - dark\n",
    "    images = images / np.broadcast_to(np.array(exp[\"diode_sum_mean\"]), images.T.shape).T\n",
    "\n",
    "im_mean = np.mean(images, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = cimshow(images)\n",
    "ax.set_title(\"Normalized and Background corrected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw beamstop mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "poly_mask = interactive.draw_polygon_mask(im_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Take poly coordinates and mask from widget\n",
    "p_coord = poly_mask.get_vertice_coordinates()\n",
    "mask = poly_mask.full_mask.astype(int)\n",
    "\n",
    "cimshow(mask)\n",
    "\n",
    "print(\"Mask coordinates: %s\" % p_coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_poly_coordinates():\n",
    "    \"\"\"\n",
    "    Dictionary that stores polygon corner coordinates of all drawn masks\n",
    "    Example: How to add masks with name \"test\":\n",
    "    mask_coordinates[\"test\"] = copy coordinates from above\n",
    "    \"\"\"\n",
    "\n",
    "    # Setup dictonary\n",
    "    mask_coordinates = dict()\n",
    "\n",
    "    mask_coordinates[\"bs_cross\"] = [[(970.6033322491838, 1035.7034550617395), (527.5411796884623, 1019.5333035084286), (12.617148197288515, 1002.8622019364727), (-60.139858829924265, 994.1121885848413), (-26.96853342189422, 1162.7330927423272), (529.1581948437935, 1182.8518341968697), (964.1352716278594, 1195.7879554395186), (968.4083162201969, 1259.459762784269), (924.0397667896182, 2057.6005935990224), (1087.1331264408084, 2070.6480623711177), (1113.3401451709547, 1599.6803482278478), (1133.0411391151633, 1201.8382747710389), (1585.701758243843, 1220.5306473819905), (2083.078220662558, 1245.3994705029263), (2063.7358026796082, 1085.1337215013402), (1505.5688837430498, 1057.5016958114118), (1135.2997394980064, 1040.9224803974546), (1175.0258546913572, -7.439510570785615), (1012.0272730816591, -7.439510570785842), (977.3530293574142, 874.0864548802089)]]\n",
    "    mask_coordinates[\"membranes\"] = [[(924.3859891002303, 989.4662819473956), (925.461764876891, 1047.4386478049537), (993.2356388065143, 1031.4215372371623), (981.4021052632468, 984.0874030640921)], [(1081.4492524926907, 992.5740831952585), (1084.676579822673, 1040.9839931449894), (1132.0107139957431, 1046.362872028293), (1166.435538848885, 1017.3169260584543), (1162.1324357422423, 982.8921012053124), (1119.1014046758148, 985.0436527586337)], [(1205.1634668086697, 986.1194285352944), (1175.0417450621705, 1003.3318409618654), (1184.7237270521168, 1033.4535627083646), (1222.3758792352407, 1033.4535627083646), (1249.270273651758, 1009.7864956218295), (1250.3460494284186, 988.2709800886157)], [(1276.1646680682752, 993.6498589719192), (1276.1646680682752, 1030.2262353783826), (1303.0590624847923, 1035.6051142616861), (1333.1807842312915, 1031.3020111550431), (1333.1807842312915, 993.6498589719192)], [(1364.3782817544516, 996.8771863019012), (1365.454057531112, 1035.6051142616861), (1403.1062097142362, 1037.7566658150074), (1420.3186221408073, 1033.4535627083646), (1414.9397432575038, 991.4983074185978)]]\n",
    "    return mask_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Which drawn masks do you want to load?\n",
    "polygon_names = [\"bs_cross\",\"membranes\"] \n",
    "mask = mask_lib.load_poly_masks(images[0].shape,load_poly_coordinates(),polygon_names)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5), sharex=True, sharey=True)\n",
    "mi, ma = np.percentile(im_mean, [1, 99])\n",
    "ax[0].imshow(im_mean * (1 - mask), vmin=mi, vmax=ma)\n",
    "ax[0].set_title(\"(1-mask)\")\n",
    "ax[1].imshow(im_mean * mask, vmin=mi, vmax=ma)\n",
    "ax[1].set_title(\"mask\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic widget to find center\n",
    "\n",
    "Try to **align** the circles to the **center of the scattering pattern**. Care! Position of beamstop might be misleading and not represent the actual center of the hologram. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set center position via widget\n",
    "ic = interactive.InteractiveCenter(images,c0=1098,c1 = 1033,rBS=95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get center positions\n",
    "center = [ic.c0, ic.c1]\n",
    "print(f\"Center:\", center)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Azimuthal integrator widget for finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup azimuthal integrator for virtual geometry\n",
    "ai = interactive.AzimuthalIntegrator(\n",
    "    dist=experimental_setup[\"ccd_dist\"],\n",
    "    detector=detector,\n",
    "    wavelength=experimental_setup[\"lambda\"],\n",
    "    poni1=center[0]\n",
    "    * experimental_setup[\"px_size\"]\n",
    "    * experimental_setup[\"binning\"],  # y (vertical)\n",
    "    poni2=center[1]\n",
    "    * experimental_setup[\"px_size\"]\n",
    "    * experimental_setup[\"binning\"],  # x (horizontal)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plotting to find  relevant q range\n",
    "I_t, q_t, phi_t = ai.integrate2d(\n",
    "    im_mean,\n",
    "    200,\n",
    "    radial_range=(0, 0.05),\n",
    "    unit=\"q_nm^-1\",\n",
    "    correctSolidAngle=False,\n",
    "    dummy=np.nan,\n",
    "    mask=mask,\n",
    "    method=\"bbox\"\n",
    ")\n",
    "az2d = xr.DataArray(I_t, dims=(\"phi\", \"q\"), coords={\"q\": q_t, \"phi\": phi_t})\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots()\n",
    "mi, ma = np.nanpercentile(I_t, [1, 99])\n",
    "az2d.plot.imshow(ax=ax, vmin=mi, vmax=ma)\n",
    "plt.title(f\"Azimuthal integration\")\n",
    "\n",
    "# Vertical lines\n",
    "# q_lines = [0.025, 0.05]\n",
    "# for qt in q_lines:\n",
    "#    ax.axvline(qt, ymin=0, ymax=180, c=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aic = interactive.AzimuthalIntegrationCenter(\n",
    "    # np.log10(images[36] - np.min(images[36]) + 1),\n",
    "    im_mean,\n",
    "    ai,\n",
    "    c0=center[0],\n",
    "    c1=center[1],\n",
    "    mask=mask,\n",
    "    im_data_range=[1, 95],\n",
    "    radial_range=(0.00, 0.05),\n",
    "    qlines=[125, 145],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get center positions\n",
    "center = [aic.c0, aic.c1]\n",
    "print(f\"Center:\", center)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Azimuthal Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup final azimuthal integrator for virtual geometry\n",
    "ai = interactive.AzimuthalIntegrator(\n",
    "    dist=experimental_setup[\"ccd_dist\"],\n",
    "    detector=detector,\n",
    "    wavelength=experimental_setup[\"lambda\"],\n",
    "    poni1=center[0]\n",
    "    * experimental_setup[\"px_size\"]\n",
    "    * experimental_setup[\"binning\"],  # y (vertical)\n",
    "    poni2=center[1]\n",
    "    * experimental_setup[\"px_size\"]\n",
    "    * experimental_setup[\"binning\"],  # x (horizontal)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Do 2d Azimuthal integration of all images and add to xarray\n",
    "list_i2d = []\n",
    "for im in tqdm(images):\n",
    "    i2d, q, chi = ai.integrate2d(im, 500, 90, dummy=np.nan, mask=mask, method=\"bbox\")\n",
    "    list_i2d.append(i2d)\n",
    "\n",
    "# Setup xarray\n",
    "data = xr.Dataset()\n",
    "data[\"images\"] = xr.DataArray(images, dims=[\"index\", \"y\", \"x\"])\n",
    "data[scan_axis] = xr.DataArray(exp[scan_axis], dims=[\"index\"])\n",
    "data[\"q\"] = q\n",
    "data[\"chi\"] = chi\n",
    "data[\"i2d\"] = xr.DataArray(list_i2d, dims=[\"index\", \"chi\", \"q\"])\n",
    "data = data.assign_attrs({\"center\": center})\n",
    "\n",
    "# If it's a pumped hysteresis, do it also for the OF case\n",
    "if pumped_hysteresis:\n",
    "    list_i2d_of = []\n",
    "    for im in tqdm(images_of):\n",
    "        i2d, q, chi = ai.integrate2d(im, 500, 90, dummy=np.nan, mask=mask)\n",
    "        list_i2d_of.append(i2d)\n",
    "\n",
    "    # Setup xarray\n",
    "    data[\"images_of\"] = xr.DataArray(images_of, dims=[\"index\", \"y\", \"x\"])\n",
    "    data[\"i2d_of\"] = xr.DataArray(list_i2d_of, dims=[\"index\", \"chi\", \"q\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select relevant chi-range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot 2d and 1d azimuthal integration to estimate the relevant chi and q range\n",
    "# which image to show?\n",
    "idx = 0\n",
    "\n",
    "# Which chi-mode? (all,hetero,homo)\n",
    "chi_mode = \"all\"\n",
    "\n",
    "# Select chi-range\n",
    "if chi_mode == \"all\":\n",
    "    sel_chi = (data.chi <= 180) * (data.chi >= -180)\n",
    "    data[\"i1d\"] = data.i2d.where(sel_chi, drop=True).mean(\"chi\")\n",
    "    if pumped_hysteresis:\n",
    "        data[\"i1d_of\"] = data.i2d_of.where(sel_chi, drop=True).mean(\"chi\")\n",
    "elif chi_mode == \"hetero\":\n",
    "    sel_chi = (data.chi < 180) * (data.chi > 95)\n",
    "    data[\"i1d\"] = data.i2d.where(sel_chi, drop=True).mean(\"chi\")\n",
    "    if pumped_hysteresis:\n",
    "        data[\"i1d_of\"] = data.i2d_of.where(sel_chi, drop=True).mean(\"chi\")\n",
    "elif chi_mode == \"homo\":\n",
    "    sel_chi = (data.chi <= -95) * (data.chi >= -180) + (data.chi <= 90) * (\n",
    "        data.chi >= 5\n",
    "    )\n",
    "    data[\"i1d\"] = data.i2d.where(sel_chi, drop=True).mean(\"chi\")\n",
    "    if pumped_hysteresis:\n",
    "        data[\"i1d_of\"] = data.i2d_of.where(sel_chi, drop=True).mean(\"chi\")\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(\n",
    "    2,\n",
    "    1,\n",
    "    figsize=(8, 8),\n",
    "    sharex=True,\n",
    ")\n",
    "mi, ma = np.nanpercentile(I_t, [0.1, 90])\n",
    "data[\"i2d\"][idx].plot.imshow(ax=ax[0], vmin=mi, vmax=ma)\n",
    "ax[0].set_title(f\"2d Azimuthal integration\")\n",
    "ax[0].grid()\n",
    "\n",
    "# Plot 1d azimuthal integration to estimate the relevant q-range\n",
    "ax[1].plot(data.q, data.i1d[idx])\n",
    "ax[1].set_yscale(\"log\")\n",
    "ax[1].set_title(\"1d Azimuthal Integration\")\n",
    "ax[1].grid()\n",
    "ax[1].set_ylabel(\"Integrated intensity\")\n",
    "ax[1].set_xlabel(\"q\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select relevant q-range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select relevant q-range for averaging\n",
    "q0, q1 = 0.01, 0.04\n",
    "binning = False\n",
    "bins = []\n",
    "\n",
    "# Get SAXS from q-range\n",
    "sel = (data.q > q0) * (data.q < q1)\n",
    "data[\"saxs\"] = data.i1d.where(sel, drop=True).mean(\"q\")\n",
    "if pumped_hysteresis:\n",
    "    data[\"saxs_of\"] = data.i1d_of.where(sel, drop=True).mean(\"q\")\n",
    "\n",
    "# Averaging of same scan axis values or binning\n",
    "if binning is True:\n",
    "    # Execute binning\n",
    "    data_bin = data.groupby_bins(scan_axis, bins).mean()\n",
    "\n",
    "    # Rename binned values, drop intervals as those cannot be save in h5\n",
    "    bin_scan_axis = scan_axis + \"_bins\"\n",
    "    data_bin = data_bin.swap_dims({bin_scan_axis: scan_axis})\n",
    "    data_bin = data_bin.drop(bin_scan_axis)\n",
    "else:\n",
    "    _, count = np.unique(data[scan_axis].values, return_counts=True)\n",
    "    if np.any(count > 1):\n",
    "        data_bin = data.groupby(scan_axis).mean()\n",
    "    else:\n",
    "        data_bin = data.swap_dims({\"index\": scan_axis})\n",
    "\n",
    "# To create log plot\n",
    "data_bin[\"i1dlog\"] = np.log10(data_bin[\"i1d\"]+ 1)\n",
    "\n",
    "# Add scan identifier\n",
    "data_bin[\"scan\"] = scan\n",
    "\n",
    "# Add AI mask\n",
    "data_bin[\"mask\"] = xr.DataArray(mask, dims=[\"y\", \"x\"])\n",
    "\n",
    "# Direction of \"time\"\n",
    "if np.sum(data[scan_axis][1:].values - data[scan_axis][0:-1].values) >= 0:\n",
    "    data_bin[\"order\"] = 1\n",
    "elif np.sum(data[scan_axis][1:].values - data[scan_axis][0:-1].values) < 0:\n",
    "    data_bin[\"order\"] = -1\n",
    "\n",
    "# Plot\n",
    "if pumped_hysteresis:\n",
    "    label_set = \"pump effect (IM-OF-OL)\"\n",
    "else:\n",
    "    label_set = \"only FEL (static)\"\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(\n",
    "    data_bin[scan_axis].values,\n",
    "    data_bin[\"saxs\"].values,\n",
    "    \"o-\",\n",
    "    label=label_set,\n",
    ")\n",
    "if pumped_hysteresis:\n",
    "    ax.plot(\n",
    "        data_bin[scan_axis].values,\n",
    "        data_bin[\"saxs_of\"].values,\n",
    "        \"o-\",\n",
    "        label=\"only FEL (OF)\",\n",
    "    )\n",
    "# ax.plot(\n",
    "#    data_bin[scan_axis].values,\n",
    "#    np.mean(data_bin[\"images\"].values * (1 - mask), axis=(1, 2)),\n",
    "#    label=\"Simple Mean\",\n",
    "# )\n",
    "\n",
    "ax.set_xlabel(scan_axis)\n",
    "ax.set_ylabel(\"Integrated SAXS\")\n",
    "ax.set_title(\"Scan: %s (Azimuthal Integration)\" % scan)\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "\n",
    "# Save fig\n",
    "fname = join(fsave, \"Hysteresis_%s_%s_%s.png\" % (scan, chi_mode, USER))\n",
    "print(\"Saving: %s\" % fname)\n",
    "plt.savefig(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hysteresis Plot\n",
    "\n",
    "## Select roi for plotting\n",
    "\n",
    "How to use:\n",
    "1. Zoom into the image and adjust your FOV until you are satisfied.\n",
    "2. Save the axes coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = cimshow(data_bin[\"images\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Takes start and end of x and y axis\n",
    "x1, x2 = ax.get_xlim()\n",
    "y2, y1 = ax.get_ylim()\n",
    "roi = np.array([int(y1), int(y2), int(x1), int(x2)])\n",
    "roi_s = np.s_[roi[0] : roi[1], roi[2] : roi[3]]\n",
    "print(f\"Roi:\", roi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Find max and min considering all images\n",
    "allmin, allmax = np.nanpercentile(data_bin[\"i2d\"].values, [1, 99.9])\n",
    "# allmin, allmax = np.nanpercentile(images - images[0], [3, 97])\n",
    "\n",
    "if allmin < .1:\n",
    "    allmin = .1\n",
    "\n",
    "print(\"Min: %d Max: %d\" % (allmin, allmax))\n",
    "\n",
    "# Create folder for gif single frames\n",
    "folder_gif = helper.create_folder(join(fsave, \"Scan_%s\" % scan))\n",
    "\n",
    "im_fnames = []\n",
    "for i in tqdm(range(len(data_bin[scan_axis].values))):\n",
    "    # Plot for averaged image\n",
    "    fig = plt.figure(figsize=(6, 10))\n",
    "    gs1 = gridspec.GridSpec(\n",
    "        4,\n",
    "        1,\n",
    "        figure=fig,\n",
    "        left=0.2,\n",
    "        bottom=0.05,\n",
    "        right=0.975,\n",
    "        top=1.1,\n",
    "        wspace=0,\n",
    "        hspace=0,\n",
    "        height_ratios=[6, 1, 2, 1],\n",
    "    )\n",
    "\n",
    "    # Plot image roi\n",
    "    ax0 = fig.add_subplot(gs1[0])\n",
    "    m = ax0.imshow(data_bin[\"images\"][i].values[roi_s]*(1-mask[roi_s]), vmin=allmin, vmax=allmax)\n",
    "    plt.colorbar(m, ax=ax0, pad=0.045, location=\"bottom\")\n",
    "\n",
    "    # Plot 1d azimuthal integration\n",
    "    ax1 = fig.add_subplot(gs1[1])\n",
    "    tmp = data_bin.i1d[i]\n",
    "    ax1.plot(data_bin.q, tmp)\n",
    "    ax1.set_xlabel(\"q\")\n",
    "    ax1.set_ylabel(\"Mean Intensity\")\n",
    "    ax1.set_xlim([q0, q1])\n",
    "    ax1.set_ylim([allmin, allmax])\n",
    "    ax1.set_yscale(\"log\")\n",
    "    ax1.grid()\n",
    "    \n",
    "    ax2 = fig.add_subplot(gs1[2])\n",
    "    vmin, vmax = np.nanpercentile(data_bin[\"i1dlog\"], [.1, 99.9])\n",
    "    data_bin[\"i1dlog\"].plot.contourf(\n",
    "        x=scan_axis,\n",
    "        y=\"q\",\n",
    "        ax=ax2,\n",
    "        cmap=\"viridis\",\n",
    "        add_colorbar=False,\n",
    "        vmin=vmin,\n",
    "        vmax=vmax,\n",
    "        levels=200,\n",
    "        ylim = [q0,q1]\n",
    "    )\n",
    "    ax2.vlines(data_bin[scan_axis].values[i], q0, q1,'r')\n",
    "    ax2.hlines(q0, data_bin[scan_axis].min(),data_bin[scan_axis].max(),'w',linestyles='dashed')\n",
    "    ax2.hlines(q1, data_bin[scan_axis].min(),data_bin[scan_axis].max(),'w',linestyles='dashed')\n",
    "\n",
    "    # Plot SAXS Intensity\n",
    "    ax3 = fig.add_subplot(gs1[3])\n",
    "    ax3.plot(data_bin[scan_axis].values, data_bin[\"saxs\"].values)\n",
    "    ax3.scatter(data_bin[scan_axis].values[i], data_bin[\"saxs\"].values[i], 20, color=\"r\")\n",
    "    ax3.set_xlabel(scan_axis)\n",
    "    ax3.set_ylabel(\"Mean intensity\")\n",
    "    ax3.grid()\n",
    "    ax3.set_xlim(data_bin[scan_axis].min(),data_bin[scan_axis].max())\n",
    "\n",
    "    # Title and fname\n",
    "    ax0.set_title(f\"%s:  %s = %s\" % (scan, scan_axis, data_bin[scan_axis].values[i]))\n",
    "\n",
    "    # Save\n",
    "    fname = join(folder_gif, \"Hysteresis_%s_%s_%03d_%s.png\" % (scan, chi_mode, i, USER))\n",
    "    im_fnames.append(fname)\n",
    "    plt.savefig(fname)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# Create gif for 1d AI\n",
    "fname = f\"SAXS_%s_%s_%s.gif\" % (scan, chi_mode, USER)\n",
    "gif_path = join(fsave, fname)\n",
    "print(\"Saving gif:%s\" % gif_path)\n",
    "helper.create_gif(im_fnames,gif_path,fps=2)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop images\n",
    "data_bin2 = data_bin.drop_vars([\"images\"])\n",
    "\n",
    "# Save log\n",
    "folder = join(fsave, \"Logs\")\n",
    "helper.create_folder(folder)\n",
    "fname = join(folder, \"Log_Hysteresis_Scan_%03d_%s_%s.nc\" % (scan_id, chi_mode, USER))\n",
    "\n",
    "print(f\"Saving:\", fname)\n",
    "data_bin2.to_netcdf(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def worker(\n",
    "    samplefolder,\n",
    "    scan,\n",
    "    mask,\n",
    "    ai,\n",
    "    scan_axis,\n",
    "    binning=None,\n",
    "    keys=None,\n",
    "    sort=False,\n",
    "):\n",
    "    # Load scan data\n",
    "    datafolder = join(BASEFOLDER, samplefolder)\n",
    "    exp = preprocess_exp(datafolder, \"_OF\", keys=keys, sort=sort)\n",
    "\n",
    "    # Load background images\n",
    "    exp_bg = preprocess_exp(datafolder, \"_BG\", keys=keys)\n",
    "\n",
    "    # Normalize images\n",
    "    dark = np.mean(np.stack(exp_bg[\"images\"]), axis=0)\n",
    "    images = np.stack(exp.images) - dark\n",
    "    images = images / np.broadcast_to(np.array(exp[\"diode_sum_mean\"]), images.T.shape).T\n",
    "\n",
    "    # Create xarray dataset\n",
    "    data = xr.Dataset()\n",
    "    data[\"images\"] = xr.DataArray(images, dims=[\"index\", \"y\", \"x\"])\n",
    "    data[scan_axis] = xr.DataArray(exp[scan_axis], dims=[\"index\"])\n",
    "\n",
    "    # Do 2d Azimuthal integration of all images and append them to list\n",
    "    list_i2d = []\n",
    "    for im in tqdm(data[\"images\"].values):\n",
    "        i2d, q, chi = ai.integrate2d(im, 500, 90, dummy=np.nan, mask=mask,method=\"bbox\")\n",
    "        list_i2d.append(i2d)\n",
    "\n",
    "    # Add to xarray\n",
    "    data[\"q\"] = q\n",
    "    data[\"chi\"] = chi\n",
    "    data[\"i2d\"] = xr.DataArray(list_i2d, dims=[\"index\", \"chi\", \"q\"])\n",
    "    data[\"i1d\"] = data.i2d.where(sel_chi, drop=True).mean(\"chi\")\n",
    "\n",
    "    # Averaging of same scan axis values or binning\n",
    "    if binning is None:\n",
    "        _, count = np.unique(data[scan_axis].values, return_counts=True)\n",
    "        if np.any(count > 1):\n",
    "            data_bin = data.groupby(scan_axis).mean()\n",
    "        else:\n",
    "            data_bin = data.swap_dims({\"index\": scan_axis})\n",
    "\n",
    "    else:\n",
    "        # Execute binning\n",
    "        data_bin = data.groupby_bins(scan_axis, bins).mean()\n",
    "\n",
    "        # Rename binned values, drop intervals as those cannot be save in h5\n",
    "        bin_scan_axis = scan_axis + \"_bins\"\n",
    "        data_bin = data_bin.swap_dims({bin_scan_axis: scan_axis})\n",
    "        data_bin = data_bin.drop(bin_scan_axis)\n",
    "\n",
    "    # Add log plot\n",
    "    data_bin[\"i1dlog\"] = np.log10(data_bin[\"i1d\"]+ 1)\n",
    "    \n",
    "    # Add AI mask\n",
    "    data_bin[\"mask\"] = xr.DataArray(mask, dims=[\"y\", \"x\"])\n",
    "\n",
    "    # Add file scan labels\n",
    "    data_bin[\"scan\"] = scan\n",
    "\n",
    "    # Direction of \"time\"\n",
    "    if np.sum(data[scan_axis][1:].values - data[scan_axis][0:-1].values) >= 0:\n",
    "        data_bin[\"order\"] = 1\n",
    "    elif np.sum(data[scan_axis][1:].values - data[scan_axis][0:-1].values) < 0:\n",
    "        data_bin[\"order\"] = -1\n",
    "\n",
    "\n",
    "    # Drop images to save disk space\n",
    "    data_save = data_bin.drop_vars([\"images\"])\n",
    "\n",
    "    # Save log\n",
    "    folder = join(fsave, \"Logs\")\n",
    "    fname = join(folder, \"Log_Hysteresis_Scan_%s_%s_%s.nc\" % (scan, chi_mode, USER))\n",
    "    print(f\"Saving:\", fname)\n",
    "    data_save.to_netcdf(fname)\n",
    "\n",
    "    return data_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Name of scans (see pad)\n",
    "scans = [\n",
    "    \"I7_006\",\n",
    "    \"I7_007\",\n",
    "    \"I7_008\",\n",
    "    \"I7_010\",\n",
    "]\n",
    "\n",
    "# Analysis options\n",
    "bins = []\n",
    "\n",
    "# Setup xarray for scans\n",
    "data_scans = []\n",
    "\n",
    "# Loop over scans\n",
    "for scan in tqdm(scans):\n",
    "    # Process data\n",
    "    samplefolder = join(sample, scan)\n",
    "    data = worker(\n",
    "        samplefolder,\n",
    "        scan,\n",
    "        mask,\n",
    "        ai,\n",
    "        scan_axis,\n",
    "        binning=None,\n",
    "        keys=extra_keys,\n",
    "        sort=False,\n",
    "    )\n",
    "\n",
    "    # Add to xarray list\n",
    "    data_scans.append(data)\n",
    "\n",
    "# Combine separate xarrays\n",
    "data_scans = xr.concat(data_scans, dim=\"scanid\")\n",
    "data_scans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Calc and plot SAXS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Do you want to norm the hysteresis?\n",
    "normalization = True\n",
    "\n",
    "# Select relevant q-range for averaging\n",
    "# q0, q1 = 0.003, 0.04\n",
    "\n",
    "# Get SAXS from q-range\n",
    "sel = (data_scans.q > q0) * (data_scans.q < q1)\n",
    "data_scans[\"saxs\"] = data_scans.i1d.where(sel, drop=True).mean(\"q\")\n",
    "\n",
    "# Plot all SAXS images individually\n",
    "for scanid in data_scans[\"scanid\"].values:\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Normalize?\n",
    "    if normalization is True:\n",
    "        tmp_data = data_scans[\"saxs\"][scanid].values\n",
    "        tmp_data = norm(data_scans[\"saxs\"][scanid].values[1:])\n",
    "    else:\n",
    "        tmp_data = data_scans[\"saxs\"][scanid].values[1:]\n",
    "\n",
    "    ax.plot(data_scans[scan_axis].values[1:], tmp_data, \"o-\")\n",
    "    ax.set_xlabel(scan_axis)\n",
    "    ax.set_ylabel(\"Integrated SAXS\")\n",
    "    ax.set_title(\"Scan: %s\" % data_scans[\"scan\"][scanid].values)\n",
    "    ax.grid()\n",
    "\n",
    "    # Save fig\n",
    "    fname = join(\n",
    "        fsave,\n",
    "        \"Hysteresis_%s_%s_%s.png\" % (data_scans[\"scan\"][scanid].values, chi_mode, USER),\n",
    "    )\n",
    "    print(\"Saving: %s\" % fname)\n",
    "    plt.savefig(fname)\n",
    "    plt.close()\n",
    "\n",
    "# Plot them together\n",
    "fig, ax = plt.subplots()\n",
    "for scanid in data_scans[\"scanid\"].values:\n",
    "    # Normalize?\n",
    "    if normalization is True:\n",
    "        tmp_data = data_scans[\"saxs\"][scanid].values\n",
    "        tmp_data = norm(tmp_data[1:])\n",
    "    else:\n",
    "        tmp_data = data_scans[\"saxs\"][scanid].values[1:]\n",
    "    ax.plot(\n",
    "        data_scans[scan_axis].values[1:],\n",
    "        tmp_data,\n",
    "        \"o-\",\n",
    "        label=data_scans[\"scan\"][scanid].values,\n",
    "    )\n",
    "\n",
    "ax.set_xlabel(scan_axis)\n",
    "ax.set_ylabel(\"Integrated SAXS\")\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "\n",
    "# Save fig\n",
    "fname = join(\n",
    "    fsave,\n",
    "    \"Hysteresis_%s_%s_%s_%s.png\"\n",
    "    % (data_scans[\"scan\"][0].values, data_scans[\"scan\"][-1].values, chi_mode, USER),\n",
    ")\n",
    "plt.savefig(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Export gif for all scans individually\n",
    "for scan_id in tqdm(data_scans[\"scanid\"].values):\n",
    "    tmp_xr = data_scans.sel(scanid = scan_id)\n",
    "    \n",
    "    if tmp_xr[\"order\"] == 1:\n",
    "        tmp_xr = tmp_xr.reindex(magnet_mean=data_scans.magnet_mean[::-1])\n",
    "\n",
    "    # Find max and min considering all images\n",
    "    allmin, allmax = np.nanpercentile(tmp_xr[\"i2d\"].values, [1, 99])\n",
    "    if allmin < .1:\n",
    "        allmin = .1\n",
    "    print(\"Min: %d Max: %d\" % (allmin, allmax))\n",
    "\n",
    "    # Create folder for gif single frames\n",
    "    folder_gif = helper.create_folder(join(fsave, \"Scan_%s\" % tmp_xr[\"scan\"].values))\n",
    "\n",
    "    # Normalize?\n",
    "    if normalization is True:\n",
    "        tmp_data = tmp_xr[\"saxs\"].values\n",
    "        tmp_data = norm(tmp_data[1:])\n",
    "    else:\n",
    "        tmp_data = tmp_xr[\"saxs\"].values\n",
    "        tmp_data = tmp_data[1:]\n",
    "\n",
    "    im_fnames = []\n",
    "    for i in tqdm(range(1, len(tmp_xr[scan_axis].values))):\n",
    "        # Plot for averaged image\n",
    "        fig = plt.figure(figsize=(6, 10))\n",
    "        gs1 = gridspec.GridSpec(\n",
    "            4,\n",
    "            1,\n",
    "            figure=fig,\n",
    "            left=0.2,\n",
    "            bottom=0.05,\n",
    "            right=0.975,\n",
    "            top=1.1,\n",
    "            wspace=0,\n",
    "            hspace=0,\n",
    "            height_ratios=[6, 1, 2, 1],\n",
    "        )\n",
    "    \n",
    "        # Plot image roi\n",
    "        ax0 = fig.add_subplot(gs1[0])\n",
    "        m = ax0.imshow(tmp_xr[\"images\"][i].values[roi_s]*(1-mask[roi_s]), vmin=allmin, vmax=allmax)\n",
    "        plt.colorbar(m, ax=ax0, pad=0.045, location=\"bottom\")\n",
    "    \n",
    "        # Plot 1d azimuthal integration\n",
    "        ax1 = fig.add_subplot(gs1[1])\n",
    "        tmp = tmp_xr.i1d[i]\n",
    "        ax1.plot(tmp_xr.q, tmp)\n",
    "        ax1.set_xlabel(\"q\")\n",
    "        ax1.set_ylabel(\"Mean Intensity\")\n",
    "        ax1.set_xlim([q0, q1])\n",
    "        ax1.set_ylim([allmin, allmax])\n",
    "        ax1.set_yscale(\"log\")\n",
    "        ax1.grid()\n",
    "        \n",
    "        ax2 = fig.add_subplot(gs1[2])\n",
    "        vmin, vmax = np.nanpercentile(tmp_xr[\"i1dlog\"], [1, 99])\n",
    "        tmp_xr[\"i1dlog\"].plot.contourf(\n",
    "            x=scan_axis,\n",
    "            y=\"q\",\n",
    "            ax=ax2,\n",
    "            cmap=\"viridis\",\n",
    "            add_colorbar=False,\n",
    "            vmin=vmin,\n",
    "            vmax=vmax,\n",
    "            levels=300,\n",
    "            ylim = [q0,q1]\n",
    "        )\n",
    "        ax2.vlines(tmp_xr[scan_axis].values[i], q0, q1,'r')\n",
    "        ax2.hlines(q0, tmp_xr[scan_axis].min(),data_bin[scan_axis].max(),'w',linestyles='dashed')\n",
    "        ax2.hlines(q1, tmp_xr[scan_axis].min(),data_bin[scan_axis].max(),'w',linestyles='dashed')\n",
    "    \n",
    "        # Plot SAXS Intensity\n",
    "        ax3 = fig.add_subplot(gs1[3])\n",
    "        ax3.plot(tmp_xr[scan_axis].values, tmp_xr[\"saxs\"].values)\n",
    "        ax3.scatter(tmp_xr[scan_axis].values[i], tmp_xr[\"saxs\"].values[i], 20, color=\"r\")\n",
    "        ax3.set_xlabel(scan_axis)\n",
    "        ax3.set_ylabel(\"Mean intensity\")\n",
    "        ax3.grid()\n",
    "        ax3.set_xlim(tmp_xr[scan_axis].min(),data_bin[scan_axis].max())\n",
    "    \n",
    "        # Title and fname\n",
    "        ax0.set_title(f\"%s:  %s = %s\" % (tmp_xr[\"scan\"].values, scan_axis, tmp_xr[scan_axis].values[i]))\n",
    "\n",
    "        # Save\n",
    "        fname = join(\n",
    "            folder_gif,\n",
    "            \"Hysteresis_%s_%03d_%s_%s.png\"\n",
    "            % (tmp_xr[\"scan\"].values, i, chi_mode, USER),\n",
    "        )\n",
    "        im_fnames.append(fname)\n",
    "        plt.savefig(fname)\n",
    "        plt.close()\n",
    "\n",
    "    # Create gif for 1d AI\n",
    "    var = [imageio.imread(file) for file in im_fnames]\n",
    "    fname = f\"Hysteresis_%s_%s_%s.gif\" % (\n",
    "        tmp_xr[\"scan\"].values,\n",
    "        chi_mode,\n",
    "        USER,\n",
    "    )\n",
    "    gif_path = join(fsave, fname)\n",
    "    print(\"Saving gif:%s\" % gif_path)\n",
    "    helper.create_gif(im_fnames,gif_path,fps=2)\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:klose-2309-cuda_ck]",
   "language": "python",
   "name": "conda-env-klose-2309-cuda_ck-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "179.1px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "300px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 493.85,
   "position": {
    "height": "40px",
    "left": "1580px",
    "right": "20px",
    "top": "120px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
